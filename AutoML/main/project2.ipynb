{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwIxHQZ8ocYjjo8zDsW6vN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install bayesian-optimization\n","# !pip install shap"],"metadata":{"id":"eue7yxOQ1TXf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Importing Libraries\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from scipy.stats import skew\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from bayes_opt import BayesianOptimization\n","from sklearn.metrics import r2_score, accuracy_score"],"metadata":{"id":"EGFVH6sM1TUH","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Preprocessing Database\n","\n","irrelevant_columns = [\n","    \"ID\", \"id\", \"Index\", \"index\", \"Serial Number\", \"serial_number\",\n","    \"Address\", \"address\", \"Href\", \"href\", \"Timestamp\", \"timestamp\",\n","    \"Creation Date\", \"creation_date\", \"Last Updated Date\", \"last_updated_date\",\n","    \"Version\", \"version\", \"Checksum\", \"checksum\", \"Year\", \"year\"\n","    \"Row ID\", \"row_id\", \"Record ID\", \"record_id\", \"Customer ID\", \"customer_id\",\n","    \"Client ID\", \"client_id\", \"Account ID\", \"account_id\", \"Transaction ID\", \"transaction_id\",\n","    \"Email\", \"email\", \"Phone Number\", \"phone_number\", \"Website\", \"website\",\n","    \"Fax\", \"fax\", \"IP Address\", \"ip_address\", \"MAC Address\", \"mac_address\",\n","    \"Social Security Number\", \"social_security_number\", \"Driver's License\", \"drivers_license\",\n","    \"ID_\", \"id_\", \"Index_\", \"index_\", \"Serial_Number\", \"serial_number_\",\n","    \"Address_\", \"address_\", \"Href_\", \"href_\", \"Timestamp_\", \"timestamp_\",\n","    \"Creation_Date\", \"creation_date_\", \"Last_Updated_Date\", \"last_updated_date_\",\n","    \"Version_\", \"version_\", \"Checksum_\", \"checksum_\",\n","    \"Row_ID\", \"row_id_\", \"Record_ID\", \"record_id_\", \"Customer_ID\", \"customer_id_\",\n","    \"Client_ID\", \"client_id_\", \"Account_ID\", \"account_id_\", \"Transaction_ID\", \"transaction_id_\",\n","    \"Email_\", \"email_\", \"Phone_Number\", \"phone_number_\", \"Website_\", \"website_\",\n","    \"Fax_\", \"fax_\", \"IP_Address\", \"ip_address_\", \"MAC_Address\", \"mac_address_\",\n","    \"Social_Security_Number\", \"social_security_number_\", \"Driver's_License\", \"drivers_license_\"\n","]\n","\n","ordinal_data = {\n","    'low':1,\n","    'medium':2,\n","    'moderate':2,\n","    'high':3,\n","    # Education Level\n","    'high school diploma': 1,\n","    'associate\\'s degree': 2,\n","    'bachelor\\'s degree': 3,\n","    'master\\'s degree': 4,\n","    'doctorate degree': 5,\n","    # Income Level\n","    'low income': 1,\n","    'middle income': 2,\n","    'high income': 3,\n","    # Customer Satisfaction\n","    'very dissatisfied': 1,\n","    'dissatisfied': 2,\n","    'neutral': 3,\n","    'satisfied': 4,\n","    'very satisfied': 5,\n","    # Likert Scale\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neither agree nor disagree': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Job Seniority\n","    'entry-level': 1,\n","    'mid-level': 2,\n","    'senior-level': 3,\n","    'executive-level': 4,\n","    # Severity of Illness/Condition\n","    'mild': 1,\n","    'moderate': 2,\n","    'severe': 3,\n","    # Temperature\n","    'cold': 1,\n","    'warm': 2,\n","    'hot': 3,\n","    'very hot': 4,\n","    # Customer Rating\n","    '1 star': 1,\n","    '2 stars': 2,\n","    '3 stars': 3,\n","    '4 stars': 4,\n","    '5 stars': 5,\n","    # Likelihood of Purchase\n","    'very unlikely': 1,\n","    'unlikely': 2,\n","    'likely': 4,\n","    'very likely': 5,\n","    # Degree of Agreement\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neutral': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Pain Scale\n","    'no pain': 1,\n","    'mild pain': 2,\n","    'moderate pain': 3,\n","    'severe pain': 4,\n","    'extreme pain': 5,\n","    # Likelihood of Recommendation\n","    'very unlikely to recommend': 1,\n","    'unlikely to recommend': 2,\n","    'likely to recommend': 4,\n","    'very likely to recommend': 5,\n","    # Quality Ratings\n","    'poor quality': 1,\n","    'fair quality': 2,\n","    'good quality': 3,\n","    'very good quality': 4,\n","    'excellent quality': 5,\n","    # Customer Service Experience\n","    'very poor': 1,\n","    'poor': 2,\n","    'average': 3,\n","    'good': 4,\n","    'excellent': 5,\n","    # Ease of Use\n","    'very difficult': 1,\n","    'difficult': 2,\n","    'easy': 4,\n","    'very easy': 5,\n","    # Likelihood of Churn\n","    'very unlikely to churn': 1,\n","    'unlikely to churn': 2,\n","    'likely to churn': 4,\n","    'very likely to churn': 5,\n","    # Satisfaction with Product/Service\n","    'not satisfied': 1,\n","    'slightly satisfied': 2,\n","    'moderately satisfied': 3,\n","    'extremely satisfied': 5,\n","    # Risk Levels\n","    'low risk': 1,\n","    'moderate risk': 2,\n","    'high risk': 3,\n","    # Performance Ratings\n","    'below expectations': 1,\n","    'meeting expectations': 2,\n","    'exceeding expectations': 3 }"],"metadata":{"id":"62g2bHfX1TPg","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data Preprocessing\n","\n","def remove_irrelevant_columns(data, irrelevant_columns):\n","  columns_to_delete = [col for col in data.columns if col in irrelevant_columns]\n","\n","  if len(columns_to_delete)>0:\n","    data.drop(columns=columns_to_delete, inplace=True)\n","\n","  return data\n","\n","\n","def remove_duplicate_values(data):\n","  if data.duplicated().any():\n","    data.drop_duplicates(inplace=True)\n","\n","  return data\n","\n","\n","def remove_constant_values(data):\n","  constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n","\n","  if len(constant_columns) > 0:\n","    data.drop(columns=constant_columns, inplace=True)\n","\n","  return data\n","\n","\n","def remove_string_numerical(data):\n","  string_num_cols = [col for col in data.columns if data[col].dtype == 'object' and data[col].str.isnumeric().all()]\n","\n","  if len(string_num_cols) > 0:\n","    data[string_num_cols] = data[string_num_cols].apply(pd.to_numeric)\n","\n","  return data\n","\n","\n","def remove_object_numerical(data):\n","  import re\n","  object_cols = data.select_dtypes(include=['object']).columns\n","\n","  if len(object_cols) > 0:\n","    for col in object_cols:\n","      numerical_values = data[col].apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+', str(x)))\n","      numeric_col = col + '_numeric'\n","      data[numeric_col] = numerical_values.apply(lambda x: float(x[0]) if x else None)\n","\n","  return data\n","\n","\n","def missing_values(data, threshold=0.3, k_neighbors=5):\n","  numerical_cols = data.select_dtypes(include=['number']).columns\n","  categorical_cols = data.select_dtypes(include=['object']).columns\n","\n","  if data.isnull().any().any():\n","      missing_percentage = data.isnull().mean()\n","\n","      if (missing_percentage < threshold).any():\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","        strategy = 'knn'\n","      else:\n","        imputer = SimpleImputer(strategy='mean')\n","        strategy = 'mean'\n","      if strategy == 'knn':\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","      else:\n","        imputer = SimpleImputer(strategy=strategy)\n","      data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n","      mode_imputer = SimpleImputer(strategy='most_frequent')\n","      data[categorical_cols] = mode_imputer.fit_transform(data[categorical_cols])\n","\n","  return data\n","\n","\n","# def convert_datetime(data):\n","#     object_cols = data.select_dtypes(include=['object']).columns\n","\n","#     if len(object_cols) > 0:\n","#         for col in object_cols:\n","#             try:\n","#                 data[col] = pd.to_datetime(data[col])\n","#                 data[col + '_numeric'] = data[col].astype('int64') // 10**9\n","#                 data.drop(columns=[col], inplace=True)\n","#             except (ValueError, TypeError):\n","#                 pass\n","\n","#     return data\n","\n","\n","def encode_objects(data):\n","  categorical_columns = data.select_dtypes(include=['object']).columns\n","\n","  if len(categorical_columns) > 0:\n","    for col in categorical_columns:\n","      unique_values_count = data[col].nunique()\n","\n","      if unique_values_count == 2:\n","        encoder = LabelEncoder()\n","        data[col] = encoder.fit_transform(data[col])\n","\n","      elif unique_values_count <= 7:     #RE\n","          if all(value in ordinal_data for value in data[col].str.lower()):\n","            data[col] = data[col].str.lower().map(ordinal_data)\n","          elif any(word in data[col].str.lower() for word in ['low', 'medium', 'moderate', 'high']):\n","            data[col] = data[col].apply(lambda x: ordinal_data[x.lower()] if x.lower() in ordinal_data else x)\n","          else:\n","            encoder = OneHotEncoder(sparse_output=False, drop='first')\n","            encoded_values = encoder.fit_transform(data[[col]])\n","            col_names = [f\"{col}_{value}\" for value in encoder.categories_[0][1:]]\n","            df = pd.DataFrame(encoded_values, columns=col_names)\n","            data = pd.concat([data, df], axis=1)\n","            data.drop(columns=[col], inplace=True)\n","\n","      #else : LabelEncoder()\n","\n","  return data\n","\n","\n","def adjust_values(data):\n","  scaler = StandardScaler()\n","  scaler.fit_transform(data)\n","  #scipy\n","  return data\n","\n","\n","#master function\n","def preprocess_data(data, threshold=0.5, k_neighbors=5):\n","\n","    data = remove_irrelevant_columns(data, irrelevant_columns)\n","    data = remove_duplicate_values(data)\n","    data = remove_constant_values(data)\n","    data = remove_string_numerical(data)\n","    data = remove_object_numerical(data)\n","    data = missing_values(data, threshold, k_neighbors)\n","    # data = convert_datetime(data)\n","    data = encode_objects(data) #\n","    # data = adjust_values(data)\n","\n","    return data"],"metadata":{"id":"jo6xEkP91TEc","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#feature selection"],"metadata":{"id":"sf3RpSxd5DH2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Model Selection\n","\n","def algorithm_type(x_var, y_var):\n","    from sklearn.utils.multiclass import type_of_target\n","    dtype = y_var.dtype    #int float object\n","    target_type = type_of_target(y_var)   #binary continuous multiclass\n","\n","    if dtype == 'object' or target_type == 'binary':\n","      problem_type = 'Classification'\n","      print('Object or Binary target variable detected !')\n","\n","    elif target_type == 'continuous':\n","      problem_type = 'Regression'\n","      print('Continuous target variable detected !')\n","\n","    elif dtype in ['int64','float64'] or target_type in ['multiclass']:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=42)\n","        rf_classifier = RandomForestClassifier()  #accuracy score\n","        rf_regressor = RandomForestRegressor()  #r2 score\n","        rf_classifier.fit(X_train, y_train)\n","        rf_regressor.fit(X_train, y_train)\n","        classifier_score = rf_classifier.score(X_test, y_test)\n","        regressor_score = rf_regressor.score(X_test, y_test)\n","        if classifier_score > regressor_score:\n","            problem_type = 'Classification'\n","        else:\n","            problem_type = 'Regression'\n","        print(f'CS:{classifier_score} , RS:{regressor_score}')\n","\n","    else:\n","        problem_type = input('''Specify problem type manually -\n","        (r for Regression / c for Classification) : ''')\n","\n","    return problem_type\n","\n","\n","def model_analysis(ptype):\n","    if ptype.lower() in ['Regression','regression', 'r']:\n","        models = [\n","            ('DecisionTreeRegressor', DecisionTreeRegressor()),\n","            ('RandomForestRegressor', RandomForestRegressor()),\n","            ('GradientBoostingRegressor', GradientBoostingRegressor())\n","        ]\n","    elif ptype.lower() in ['Classification','classification', 'c']:\n","        models = [\n","            ('DecisionTreeClassifier', DecisionTreeClassifier()),\n","            ('RandomForestClassifier', RandomForestClassifier()),\n","            ('GradientBoostingClassifier', GradientBoostingClassifier())\n","        ]\n","    else:\n","        raise ValueError('Invalid problem type specified.')\n","\n","    return models\n","\n","\n","def model_selection(models, X, y, problem_type, cv=3):   #sampling original data\n","    from sklearn.metrics import accuracy_score, r2_score\n","    best_model = None\n","    best_score = float('-inf') if problem_type == 'regression' else 0\n","\n","    for name, model in models:\n","        scoring = 'r2' if problem_type == 'regression' else 'accuracy'\n","        scores = cross_val_score(model, X, y, scoring=scoring, cv=cv)\n","        mean_score = scores.mean()\n","        if problem_type == 'regression' and mean_score > best_score:\n","            best_score = mean_score\n","            best_model = model\n","        elif problem_type == 'classification' and mean_score > best_score:\n","            best_score = mean_score\n","            best_model = model\n","    return best_model"],"metadata":{"id":"8MYrNEmTewqV","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Optimizers\n","\n","# # Decision Tree Regressor Optimization\n","# def optimize_dtr(X_train, X_test, y_train, y_test):\n","#     def optimize_dtr_inner(max_depth, min_samples_split, min_samples_leaf):\n","#         dtr = DecisionTreeRegressor(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                      min_samples_leaf=int(min_samples_leaf))\n","#         dtr.fit(X_train, y_train)\n","#         y_pred = dtr.predict(X_test)\n","#         return r2_score(y_test, y_pred)\n","\n","#     dtr_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_dtr = BayesianOptimization(f=optimize_dtr_inner, pbounds=dtr_bounds, random_state=42)\n","#     bayes_dtr.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_dtr, bayes_dtr.max['target']\n","\n","# # Random Forest Regressor Optimization\n","# def optimize_rfr(X_train, X_test, y_train, y_test):\n","#     def optimize_rfr_inner(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","#         rfr = RandomForestRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth),\n","#                                      min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","#         rfr.fit(X_train, y_train)\n","#         y_pred = rfr.predict(X_test)\n","#         return r2_score(y_test, y_pred)\n","\n","#     rfr_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_rfr = BayesianOptimization(f=optimize_rfr_inner, pbounds=rfr_bounds, random_state=42)\n","#     bayes_rfr.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_rfr, bayes_rfr.max['target']\n","\n","# # Gradient Boosting Regressor Optimization\n","# def optimize_gbr(X_train, X_test, y_train, y_test):\n","#     def optimize_gbr_inner(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","#         gbr = GradientBoostingRegressor(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","#                                          max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                          min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","#         gbr.fit(X_train, y_train)\n","#         y_pred = gbr.predict(X_test)\n","#         return r2_score(y_test, y_pred)\n","\n","#     gbr_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","#                   'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","#     bayes_gbr = BayesianOptimization(f=optimize_gbr_inner, pbounds=gbr_bounds, random_state=42)\n","#     bayes_gbr.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_gbr, bayes_gbr.max['target']\n","\n","\n","# # Decision Tree Classifier Optimization\n","# def optimize_dtc(X_train, X_test, y_train, y_test):\n","#     def optimize_dtc_inner(max_depth, min_samples_split, min_samples_leaf):\n","#         dtc = DecisionTreeClassifier(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                       min_samples_leaf=int(min_samples_leaf))\n","#         dtc.fit(X_train, y_train)\n","#         y_pred = dtc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred)\n","\n","#     dtc_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_dtc = BayesianOptimization(f=optimize_dtc_inner, pbounds=dtc_bounds, random_state=42)\n","#     bayes_dtc.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_dtc, bayes_dtc.max['target']\n","\n","# # Random Forest Classifier Optimization\n","# def optimize_rfc(X_train, X_test, y_train, y_test):\n","#     def optimize_rfc_inner(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","#         rfc = RandomForestClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth),\n","#                                       min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","#         rfc.fit(X_train, y_train)\n","#         y_pred = rfc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred)\n","\n","#     rfc_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_rfc = BayesianOptimization(f=optimize_rfc_inner, pbounds=rfc_bounds, random_state=42)\n","#     bayes_rfc.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_rfc, bayes_rfc.max['target']\n","\n","# # Gradient Boosting Classifier Optimization\n","# def optimize_gbc(X_train, X_test, y_train, y_test):\n","#     def optimize_gbc_inner(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","#         gbc = GradientBoostingClassifier(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","#                                          max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                          min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","#         gbc.fit(X_train, y_train)\n","#         y_pred = gbc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred)\n","\n","#     gbc_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","#                   'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","#     bayes_gbc = BayesianOptimization(f=optimize_gbc_inner, pbounds=gbc_bounds, random_state=42)\n","#     bayes_gbc.maximize(init_points=10, n_iter=10)\n","\n","#     return bayes_gbc, bayes_gbc.max['target']"],"metadata":{"cellView":"form","id":"Z88XluyPewoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Optimizer Functions\n","\n","# Decision Tree Regressor Optimization\n","def optimize_dtr(X_train, X_test, y_train, y_test):\n","    def dtr_optimizer(max_depth, min_samples_split, min_samples_leaf):\n","        dtr = DecisionTreeRegressor(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                     min_samples_leaf=int(min_samples_leaf))\n","        dtr.fit(X_train, y_train)\n","        y_pred = dtr.predict(X_test)\n","        return r2_score(y_test, y_pred), {'max_depth': int(max_depth),\n","                                          'min_samples_split': int(min_samples_split),\n","                                          'min_samples_leaf': int(min_samples_leaf)}\n","\n","    dtr_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_dtr = BayesianOptimization(f=dtr_optimizer, pbounds=dtr_bounds, random_state=42)\n","    bayes_dtr.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_dtr.max['params']\n","\n","    dtr_final = DecisionTreeClassifier(max_depth=int(round(best_params['max_depth'])),\n","                                       min_samples_split=int(best_params['min_samples_split']),\n","                                       min_samples_leaf=int(best_params['min_samples_leaf']))\n","    dtr_final.fit(X_train, y_train)\n","\n","    y_pred = dtr_final.predict(X_test)\n","    performance = r2_score(y_test, y_pred)\n","\n","    return dtr_final, performance\n","\n","\n","# Random Forest Regressor Optimization\n","def optimize_rfr(X_train, X_test, y_train, y_test):\n","    def rfr_optimizer(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","        rfr = RandomForestRegressor(n_estimators=int(round(n_estimators)), max_depth=int(round(max_depth)),\n","                                     min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","        rfr.fit(X_train, y_train)\n","        y_pred = rfr.predict(X_test)\n","        return r2_score(y_test, y_pred)\n","\n","    rfr_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_rfr = BayesianOptimization(f=rfr_optimizer, pbounds=rfr_bounds, random_state=42)\n","    bayes_rfr.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_rfr.max['params']\n","\n","    rfr_final = RandomForestRegressor(n_estimators=int(round(best_params['n_estimators'])),\n","                                      max_depth=int(round(best_params['max_depth'])),\n","                                      min_samples_split=int(best_params['min_samples_split']),\n","                                      min_samples_leaf=int(best_params['min_samples_leaf']))\n","    rfr_final.fit(X_train, y_train)\n","\n","    y_pred = rfr_final.predict(X_test)\n","    performance = r2_score(y_test, y_pred)\n","\n","    return rfr_final, performance\n","\n","\n","# Gradient Boosting Regressor Optimization\n","def optimize_gbr(X_train, X_test, y_train, y_test):\n","    def gbr_optimizer(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","        gbr = GradientBoostingRegressor(n_estimators=int(round(n_estimators)), learning_rate=learning_rate,\n","                                         max_depth=int(round(max_depth)), min_samples_split=int(min_samples_split),\n","                                         min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","        gbr.fit(X_train, y_train)\n","        y_pred = gbr.predict(X_test)\n","        return r2_score(y_test, y_pred)\n","\n","    gbr_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","                  'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","    bayes_gbr = BayesianOptimization(f=gbr_optimizer, pbounds=gbr_bounds, random_state=42)\n","    bayes_gbr.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_gbr.max['params']\n","\n","    gbr_final = GradientBoostingRegressor(n_estimators=int(round(best_params['n_estimators'])),\n","                                           learning_rate=best_params['learning_rate'],\n","                                           max_depth=int(round(best_params['max_depth'])),\n","                                           min_samples_split=int(best_params['min_samples_split']),\n","                                           min_samples_leaf=int(best_params['min_samples_leaf']),\n","                                           subsample=best_params['subsample'])\n","    gbr_final.fit(X_train, y_train)\n","\n","    y_pred = gbr_final.predict(X_test)\n","    performance = r2_score(y_test, y_pred)\n","\n","    return gbr_final, performance\n","\n","\n","# Decision Tree Classifier Optimization\n","def optimize_dtc(X_train, X_test, y_train, y_test):\n","    def dtc_optimizer(max_depth, min_samples_split, min_samples_leaf):\n","        dtc = DecisionTreeClassifier(max_depth=int(round(max_depth)), min_samples_split=int(min_samples_split),\n","                                      min_samples_leaf=int(min_samples_leaf))\n","        dtc.fit(X_train, y_train)\n","        y_pred = dtc.predict(X_test)\n","        return accuracy_score(y_test, y_pred)\n","\n","    dtc_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_dtc = BayesianOptimization(f=dtc_optimizer, pbounds=dtc_bounds, random_state=42)\n","    bayes_dtc.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_dtc.max['params']\n","\n","    dtc_final = DecisionTreeClassifier(max_depth=int(round(best_params['max_depth'])),\n","                                       min_samples_split=int(best_params['min_samples_split']),\n","                                       min_samples_leaf=int(best_params['min_samples_leaf']))\n","    dtc_final.fit(X_train, y_train)\n","\n","    y_pred = dtc_final.predict(X_test)\n","    performance = accuracy_score(y_test, y_pred)\n","\n","    return dtc_final, performance\n","\n","\n","# Random Forest Classifier Optimization\n","def optimize_rfc(X_train, X_test, y_train, y_test):\n","    def rfc_optimizer(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","        rfc = RandomForestClassifier(n_estimators=int(round(n_estimators)), max_depth=int(round(max_depth)),\n","                                      min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","        rfc.fit(X_train, y_train)\n","        y_pred = rfc.predict(X_test)\n","        return accuracy_score(y_test, y_pred)\n","\n","    rfc_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_rfc = BayesianOptimization(f=rfc_optimizer, pbounds=rfc_bounds, random_state=42)\n","    bayes_rfc.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_rfc.max['params']\n","\n","    rfc_final = RandomForestClassifier(n_estimators=int(round(best_params['n_estimators'])),\n","                                       max_depth=int(round(best_params['max_depth'])),\n","                                       min_samples_split=int(best_params['min_samples_split']),\n","                                       min_samples_leaf=int(best_params['min_samples_leaf']))\n","    rfc_final.fit(X_train, y_train)\n","\n","    y_pred = rfc_final.predict(X_test)\n","    performance = accuracy_score(y_test, y_pred)\n","\n","    return rfc_final, performance\n","\n","\n","# Gradient Boosting Classifier Optimization\n","def optimize_gbc(X_train, X_test, y_train, y_test):\n","    def gbc_optimizer(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","        gbc = GradientBoostingClassifier(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","                                         max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                         min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","        gbc.fit(X_train, y_train)\n","        y_pred = gbc.predict(X_test)\n","        return accuracy_score(y_test, y_pred), {'n_estimators': int(n_estimators),\n","                                                'learning_rate': learning_rate,\n","                                                'max_depth': int(max_depth),\n","                                                'min_samples_split': int(min_samples_split),\n","                                                'min_samples_leaf': int(min_samples_leaf),\n","                                                'subsample': subsample}\n","\n","    gbc_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","                  'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","    bayes_gbc = BayesianOptimization(f=gbc_optimizer, pbounds=gbc_bounds, random_state=42)\n","    bayes_gbc.maximize(init_points=10, n_iter=10)\n","    best_params = bayes_gbc.max['params']\n","    accuracy = bayes_gbc.max['target']\n","\n","    gbc_final = GradientBoostingClassifier(n_estimators=int(round(best_params['n_estimators'])),\n","                                           learning_rate=best_params['learning_rate'],\n","                                           max_depth=int(round(best_params['max_depth'])),\n","                                           min_samples_split=int(best_params['min_samples_split']),\n","                                           min_samples_leaf=int(best_params['min_samples_leaf']),\n","                                           subsample=best_params['subsample'])\n","    gbc_final.fit(X_train, y_train)\n","\n","    y_pred = gbc_final.predict(X_test)\n","    performance = accuracy_score(y_test, y_pred)\n","\n","    return gbc_final, performance"],"metadata":{"cellView":"form","id":"V-rcz5Xp1897"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Model Optimization and Training\n","def optimize_model(algorithm, model, X_train, X_test, y_train, y_test):\n","\n","    if algorithm.lower() == 'regression':\n","      if isinstance(model, DecisionTreeRegressor):\n","          optimized_model, score = optimize_dtr(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, RandomForestRegressor):\n","          optimized_model, score = optimize_rfr(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, GradientBoostingRegressor):\n","          optimized_model, score = optimize_gbr(X_train, X_test, y_train, y_test)\n","\n","    elif algorithm.lower() == 'classification':\n","      if isinstance(model, DecisionTreeClassifier):\n","          optimized_model, score = optimize_dtc(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, RandomForestClassifier):\n","          optimized_model, score = optimize_rfc(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, GradientBoostingClassifier):\n","          optimized_model, score = optimize_gbc(X_train, X_test, y_train, y_test)\n","\n","    else:\n","        print('No model selected !!')\n","        optimized_model = None\n","\n","    return optimized_model, score"],"metadata":{"cellView":"form","id":"Hxkg1C1Bewjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = pd.read_csv('powerplant_energy_data.csv')\n","\n","data = preprocess_data(dataset)\n","\n","print(\"Column Names with Indexes:\")\n","for idx, col_name in enumerate(data.columns):\n","    print(f\"Index {idx}: {col_name}\")\n","target_col_idx = int(input(\"Enter the index of the target variable column: \"))"],"metadata":{"id":"3ihSGKyP1TR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = data.drop(data.columns[target_col_idx], axis=1)\n","y = data.iloc[:, target_col_idx]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"rmJGtl8tewZd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["algorithm = algorithm_type(X, y)\n","print(f'{algorithm} Analysis : ')\n","\n","models = model_analysis(algorithm)\n","print(models)\n","\n","best_model = model_selection(models, X, y, algorithm)\n","print(f'Model selected : {best_model} !!')\n","\n","final_model, performace = optimize_model(algorithm, best_model, X_train, X_test, y_train, y_test)\n","print(f\"Model : {best_model}\")\n","print(f\"Performance : {performace}\")"],"metadata":{"id":"_TKSPcCDewXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9nKqBBNaewGh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xVxljyp3TnkX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BejcLuZOTnhC"},"execution_count":null,"outputs":[]}]}