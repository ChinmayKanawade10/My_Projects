{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j6laVZ4aCVXs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.impute import KNNImputer, SimpleImputer\n","from scipy.stats import zscore\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn import preprocessing\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"usbzIBiPCYay"},"outputs":[],"source":["#@title Data Cleaning\n","class DataCleaning:\n","    def __init__(self, duplicates=True, missing_num=None, missing_categ=None, outliers_method=None, scaler=None, extract_datetime=False, encode_categ=None):\n","        self.duplicates = duplicates\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","        self.outliers_method = outliers_method\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","        self.encode_categ = encode_categ\n","\n","    def fit_transform(self, df):\n","        original_dtypes = df.dtypes\n","\n","        if self.duplicates:\n","            df = Duplicates().handle(df)\n","        if self.missing_num or self.missing_categ:\n","            df = MissingValues(self.missing_num, self.missing_categ).handle(df)\n","        if self.outliers_method:\n","            df = Outliers().handle(df)\n","        if self.scaler or self.extract_datetime:\n","            df = Adjust(self.scaler, self.extract_datetime).handle(df)\n","        if self.encode_categ:\n","            df = EncodeCateg(self.encode_categ).handle(df)\n","\n","        for col in df.columns:\n","            if original_dtypes[col] in [np.float64, np.int64]:\n","                df[col] = df[col].astype(original_dtypes[col])\n","\n","        return df\n","\n","\n","class Duplicates:\n","    def handle(self, df):\n","        df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","\n","class MissingValues:\n","    def __init__(self, missing_num=None, missing_categ=None):\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","\n","    def handle(self, df, _n_neighbors=5):\n","        if self.missing_num or self.missing_categ:\n","            if df.isna().sum().sum() != 0:\n","                if self.missing_num:\n","                    df = self._handle_missing_num(df, _n_neighbors)\n","                if self.missing_categ:\n","                    df = self._handle_missing_categ(df, _n_neighbors)\n","        return df\n","\n","    def _handle_missing_num(self, df, _n_neighbors):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        for col in num_cols:\n","            if self.missing_num in ['auto', 'knn']:\n","                imputer = KNNImputer(n_neighbors=_n_neighbors)\n","                df[col] = imputer.fit_transform(df[[col]])\n","                df[col] = df[col].round().astype('Int64')\n","        return df\n","\n","    def _handle_missing_categ(self, df, _n_neighbors):\n","        cat_cols = set(df.columns) - set(df.select_dtypes(include=np.number).columns)\n","        for col in cat_cols:\n","            if self.missing_categ in ['auto', 'logreg', 'most_frequent']:\n","                if self.missing_categ == 'most_frequent':\n","                    strategy = self.missing_categ\n","                else:\n","                    strategy = 'constant'\n","                imputer = SimpleImputer(strategy=strategy)\n","                df[col] = imputer.fit_transform(df[[col]])\n","        return df\n","\n","\n","class Outliers:\n","    def handle(self, df):\n","        df = self.replace_outliers(df)\n","        return df\n","\n","    def detect_outliers(self, df):\n","        Q1 = df.quantile(0.25)\n","        Q3 = df.quantile(0.75)\n","        IQR = Q3 - Q1\n","        return ((df \u003c (Q1 - 1.5 * IQR)) | (df \u003e (Q3 + 1.5 * IQR))).any(axis=1)\n","\n","    def replace_outliers(self, df, replacement_value=None):\n","        if replacement_value is None:\n","            replacement_value = df.median(numeric_only=True)\n","        for col in df.columns:\n","            if df[col].dtype != 'O':\n","                Q1 = df[col].quantile(0.25)\n","                Q3 = df[col].quantile(0.75)\n","                IQR = Q3 - Q1\n","                lower_bound = Q1 - 1.5 * IQR\n","                upper_bound = Q3 + 1.5 * IQR\n","                df[col] = np.where((df[col] \u003c lower_bound) | (df[col] \u003e upper_bound), replacement_value[col], df[col])\n","        return df\n","\n","\n","class Adjust:\n","    def __init__(self, scaler=None, extract_datetime=False):\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","\n","    def handle(self, df):\n","        if self.scaler or self.extract_datetime:\n","            df = self._convert_datetime(df)\n","            if self.scaler:\n","                if self.scaler in ['MinMax', 'Standard', 'Robust']:\n","                    scaler = preprocessing.__getattribute__(self.scaler+'Scaler')()\n","                    df[df.columns] = scaler.fit_transform(df[df.columns])\n","        return df\n","\n","    def _convert_datetime(self, df):\n","        cols = set(df.columns) \u0026 set(self.extract_datetime)\n","        for col in cols:\n","            try:\n","                df[col] = pd.to_datetime(df[col], errors='coerce')\n","                if self.extract_datetime:\n","                    df[col + '_year'] = df[col].dt.year\n","                    df[col + '_month'] = df[col].dt.month\n","                    df[col + '_day'] = df[col].dt.day\n","                    df.drop(columns=[col], inplace=True)\n","            except:\n","                pass\n","        return df\n","\n","\n","class EncodeCateg:\n","    def __init__(self, encode_categ=None):\n","        self.encode_categ = encode_categ\n","\n","    def handle(self, df):\n","        if self.encode_categ:\n","            if self.encode_categ == 'auto':\n","                self._auto_encode(df)\n","            elif isinstance(self.encode_categ, list):\n","                for col in self.encode_categ:\n","                    if col in df.columns:\n","                        self._auto_encode(df, col)\n","        return df\n","\n","    def _auto_encode(self, df, col=None):\n","        if col:\n","            if df[col].dtype == 'O':\n","                if len(df[col].unique()) \u003c= 10:\n","                    df[col] = df[col].astype('category')\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col], drop_first=True)\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        else:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) \u003c= 10:\n","                    df[col] = df[col].astype('category')\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col], drop_first=True)\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KcAeUxmSCYdz","outputId":"7a4cee37-95e5-4926-aaa4-743989bc5ccb"},"outputs":[{"name":"stdout","output_type":"stream","text":["original data info :\n","\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 4587 entries, 0 to 4586\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ApplicantIncome    4157 non-null   float64\n"," 1   CoapplicantIncome  4587 non-null   float64\n"," 2   LoanAmount         4145 non-null   float64\n"," 3   Loan_Amount_Term   4587 non-null   int64  \n"," 4   Credit_History     4587 non-null   int64  \n"," 5   Education          4587 non-null   object \n"," 6   Property_Area      4587 non-null   object \n"," 7   Loan_Status        4587 non-null   object \n","dtypes: float64(3), int64(2), object(3)\n","memory usage: 286.8+ KB\n","None\n","\n","Outliers in original dataset :\n","ApplicantIncome       True\n","CoapplicantIncome     True\n","LoanAmount            True\n","Loan_Amount_Term     False\n","Credit_History       False\n","dtype: bool\n"]}],"source":["data = pd.read_csv(\"loan_data.csv\")\n","print('original data info :')\n","print(data.info())\n","def detect_outliers_iqr(data):\n","    outliers = pd.DataFrame()\n","    for column in data.columns:\n","        if data[column].dtype in ['int64', 'float64']:  # Check if column is numerical\n","            q1 = data[column].quantile(0.25)\n","            q3 = data[column].quantile(0.75)\n","            iqr = q3 - q1\n","            lower_bound = q1 - 1.5 * iqr\n","            upper_bound = q3 + 1.5 * iqr\n","            column_outliers = data[(data[column] \u003c lower_bound) | (data[column] \u003e upper_bound)][column]\n","            outliers = pd.concat([outliers, column_outliers], axis=1)\n","    return outliers\n","\n","outliers = detect_outliers_iqr(data)\n","print()\n","print('Outliers in original dataset :')\n","print(outliers.any())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fA9UIKdA8sE2"},"outputs":[],"source":["clean_data = DataCleaning(duplicates=True,missing_num='knn',missing_categ='most_frequent',outliers_method=True,\n","                                scaler='minMax',extract_datetime='year',encode_categ='auto')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H9G1iRceCYhI","outputId":"4756bd27-3f25-4cb0-dbea-9f760bcfff91"},"outputs":[{"name":"stdout","output_type":"stream","text":["cleaned data info :\n","\u003cclass 'pandas.core.frame.DataFrame'\u003e\n","RangeIndex: 4587 entries, 0 to 4586\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ApplicantIncome    4587 non-null   float64\n"," 1   CoapplicantIncome  4587 non-null   float64\n"," 2   LoanAmount         4587 non-null   float64\n"," 3   Loan_Amount_Term   4587 non-null   int64  \n"," 4   Credit_History     4587 non-null   int64  \n"," 5   Education          4587 non-null   object \n"," 6   Property_Area      4587 non-null   object \n"," 7   Loan_Status        4587 non-null   object \n","dtypes: float64(3), int64(2), object(3)\n","memory usage: 286.8+ KB\n","None\n","\n","Outliers in cleaned dataset :\n","ApplicantIncome      False\n","CoapplicantIncome    False\n","LoanAmount           False\n","Loan_Amount_Term     False\n","Credit_History       False\n","dtype: bool\n"]}],"source":["cleaned_data = clean_data.fit_transform(data)\n","print('cleaned data info :')\n","print(cleaned_data.info())\n","\n","def detect_outliers_iqr(data):\n","    outliers = pd.DataFrame()\n","    for column in data.columns:\n","        if data[column].dtype in ['int64', 'float64']:\n","            q1 = data[column].quantile(0.25)\n","            q3 = data[column].quantile(0.75)\n","            iqr = q3 - q1\n","            lower_bound = q1 - 1.5 * iqr\n","            upper_bound = q3 + 1.5 * iqr\n","            column_outliers = data[(data[column] \u003c lower_bound) | (data[column] \u003e upper_bound)][column]\n","            outliers = pd.concat([outliers, column_outliers], axis=1)\n","    return outliers\n","\n","outliers = detect_outliers_iqr(cleaned_data)\n","print()\n","print('Outliers in cleaned dataset :')\n","print(outliers.any())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NkThTxRCtYKD"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLJN4lF3tYGt"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5WlXGmCtYEa"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bYuTsV_oKMoK"},"outputs":[],"source":["from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from sklearn.svm import SVR, SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import r2_score, accuracy_score\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ez4oTBL1vle4"},"outputs":[],"source":["import pandas as pd\n","\n","reg_data = pd.read_csv('powerplant_energy_data.csv')\n","class_data = pd.read_csv('thyroid_cancer_data.csv')\n","\n","X_reg = reg_data.drop('energy_output', axis=1)\n","y_reg = reg_data['energy_output']\n","\n","X_class = class_data.drop('diagnosis', axis=1)\n","y_class = class_data['diagnosis']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5084,"status":"ok","timestamp":1709633090827,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"},"user_tz":-330},"id":"2X8D8LSRvBgY","outputId":"46334141-af9f-4225-da8e-feb5e6b081dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score for Regression: 0.9451894316423902\n","Best Parameters for Regression: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 2}\n","\n","Accuracy for Classification: 0.9210526315789473\n","Best Parameters for Classification: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5}\n"]}],"source":["# Hyperparameter tuning grid for Decision Tree Regressor\n","dt_regressor_params = {\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Hyperparameter tuning grid for Decision Tree Classifier\n","dt_classifier_params = {\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Decision Tree Regressor on reg_data\n","X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n","dt_regressor = DecisionTreeRegressor(random_state=0)\n","grid_regressor = GridSearchCV(dt_regressor, dt_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X_reg_train, y_reg_train)\n","y_reg_pred = grid_regressor.best_estimator_.predict(X_reg_test)\n","r2 = r2_score(y_reg_test, y_reg_pred)\n","print(\"R2 score for Regression:\", r2)\n","print(\"Best Parameters for Regression:\", grid_regressor.best_params_)\n","\n","# Decision Tree Classifier on class_data\n","X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n","dt_classifier = DecisionTreeClassifier(random_state=0)\n","grid_classifier = GridSearchCV(dt_classifier, dt_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X_class_train, y_class_train)\n","y_class_pred = grid_classifier.best_estimator_.predict(X_class_test)\n","accuracy = accuracy_score(y_class_test, y_class_pred)\n","print(\"\\nAccuracy for Classification:\", accuracy)\n","print(\"Best Parameters for Classification:\", grid_classifier.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136969,"status":"ok","timestamp":1709633354011,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"},"user_tz":-330},"id":"AQqlaSodzHxC","outputId":"2933651e-7a56-44eb-a5f5-ae67ccf25187"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score for Regression: 0.9632158655441234\n","Best Parameters for Regression: {'bootstrap': True, 'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 30}\n","\n","Accuracy for Classification: 0.9736842105263158\n","Best Parameters for Classification: {'bootstrap': True, 'max_depth': 15, 'min_samples_leaf': 2, 'n_estimators': 10}\n"]}],"source":["# Hyperparameter tuning grid for Random Forest Regressor\n","rf_regressor_params = {\n","    'n_estimators': [10, 20, 30],\n","    'max_depth': [15, 20, 30, 50],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    'bootstrap': [True, False]\n","}\n","\n","# Hyperparameter tuning grid for Random Forest Classifier\n","rf_classifier_params = {\n","    'n_estimators': [10, 20, 30],\n","    'max_depth': [15, 20, 30, 50],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    'bootstrap': [True, False]\n","}\n","\n","# Random Forest Regressor on reg_data\n","X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n","rf_regressor = RandomForestRegressor(random_state=0)\n","grid_regressor = GridSearchCV(rf_regressor, rf_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X_reg_train, y_reg_train)\n","y_reg_pred = grid_regressor.best_estimator_.predict(X_reg_test)\n","r2 = r2_score(y_reg_test, y_reg_pred)\n","print(\"R2 score for Regression:\", r2)\n","print(\"Best Parameters for Regression:\", grid_regressor.best_params_)\n","\n","# Random Forest Classifier on class_data\n","X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n","rf_classifier = RandomForestClassifier(random_state=0)\n","grid_classifier = GridSearchCV(rf_classifier, rf_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X_class_train, y_class_train)\n","y_class_pred = grid_classifier.best_estimator_.predict(X_class_test)\n","accuracy = accuracy_score(y_class_test, y_class_pred)\n","print(\"\\nAccuracy for Classification:\", accuracy)\n","print(\"Best Parameters for Classification:\", grid_classifier.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368158,"status":"ok","timestamp":1709633802512,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"},"user_tz":-330},"id":"orPi8Eob2h51","outputId":"dc3a6160-be4f-4644-ef4d-75d15c731137"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score for Regression: 0.9675191975526548\n","Best Parameters for Regression: {'learning_rate': 0.2, 'max_depth': 5, 'min_samples_split': 4, 'n_estimators': 150}\n","\n","Accuracy for Classification: 0.9385964912280702\n","Best Parameters for Classification: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 100, 'subsample': 0.9}\n"]}],"source":["# Hyperparameter tuning grid for GBM Regressor\n","gbm_regressor_params = {\n","    'n_estimators': [50, 100, 150],\n","    'learning_rate': [0.05, 0.1, 0.2],\n","    'max_depth': [3, 4, 5],\n","    'min_samples_split': [2, 3, 4]\n","}\n","\n","# Hyperparameter tuning grid for GBM Classifier\n","gbm_classifier_params = {\n","    'n_estimators': [50, 100, 150],\n","    'learning_rate': [0.05, 0.1, 0.2],\n","    'max_depth': [3, 4, 5],\n","    'min_samples_split': [2, 3, 4],\n","    'subsample': [0.8, 0.9, 1.0]\n","}\n","\n","# GBM Regressor on reg_data\n","X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n","gbm_regressor = GradientBoostingRegressor(random_state=0)\n","grid_regressor = GridSearchCV(gbm_regressor, gbm_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X_reg_train, y_reg_train)\n","y_reg_pred = grid_regressor.best_estimator_.predict(X_reg_test)\n","r2 = r2_score(y_reg_test, y_reg_pred)\n","print(\"R2 score for Regression:\", r2)\n","print(\"Best Parameters for Regression:\", grid_regressor.best_params_)\n","\n","# GBM Classifier on class_data\n","X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n","gbm_classifier = GradientBoostingClassifier(random_state=0)\n","grid_classifier = GridSearchCV(gbm_classifier, gbm_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X_class_train, y_class_train)\n","y_class_pred = grid_classifier.best_estimator_.predict(X_class_test)\n","accuracy = accuracy_score(y_class_test, y_class_pred)\n","print(\"\\nAccuracy for Classification:\", accuracy)\n","print(\"Best Parameters for Classification:\", grid_classifier.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"THq-PL0L2iFP"},"outputs":[{"name":"stdout","output_type":"stream","text":["R2 score for Regression: 0.9291343762670312\n","Best Parameters for Regression: {'C': 1, 'epsilon': 0.2, 'kernel': 'linear'}\n"]}],"source":["# Hyperparameter tuning grid for SVM Regressor\n","svm_regressor_params = {\n","    'kernel': ['linear', 'poly', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'epsilon': [0.1, 0.2, 0.5]\n","}\n","\n","# Hyperparameter tuning grid for SVM Classifier\n","svm_classifier_params = {\n","    'kernel': ['linear', 'poly', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'gamma': ['scale', 'auto'],\n","    'class_weight': ['balanced', None]\n","}\n","\n","# SVM Regressor on reg_data\n","X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n","svm_regressor = SVR()\n","grid_regressor = GridSearchCV(svm_regressor, svm_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X_reg_train, y_reg_train)\n","y_reg_pred = grid_regressor.best_estimator_.predict(X_reg_test)\n","r2 = r2_score(y_reg_test, y_reg_pred)\n","print(\"R2 score for Regression:\", r2)\n","print(\"Best Parameters for Regression:\", grid_regressor.best_params_)\n","\n","# SVM Classifier on class_data\n","X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n","svm_classifier = SVC()\n","grid_classifier = GridSearchCV(svm_classifier, svm_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X_class_train, y_class_train)\n","y_class_pred = grid_classifier.best_estimator_.predict(X_class_test)\n","accuracy = accuracy_score(y_class_test, y_class_pred)\n","print(\"\\nAccuracy for Classification:\", accuracy)\n","print(\"Best Parameters for Classification:\", grid_classifier.best_params_)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}