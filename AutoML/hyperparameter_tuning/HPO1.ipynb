{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP9zAvuJnt/seDksAwBLpcL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j6laVZ4aCVXs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.impute import KNNImputer, SimpleImputer\n","from scipy.stats import zscore\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn import preprocessing\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns"]},{"cell_type":"code","source":["#@title Data Cleaning\n","class DataCleaning:\n","    def __init__(self, duplicates=True, missing_num=None, missing_categ=None, outliers_method=None, scaler=None, extract_datetime=False, encode_categ=None):\n","        self.duplicates = duplicates\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","        self.outliers_method = outliers_method\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","        self.encode_categ = encode_categ\n","\n","    def fit_transform(self, df):\n","        original_dtypes = df.dtypes\n","\n","        if self.duplicates:\n","            df = Duplicates().handle(df)\n","        if self.missing_num or self.missing_categ:\n","            df = MissingValues(self.missing_num, self.missing_categ).handle(df)\n","        if self.outliers_method:\n","            df = Outliers().handle(df)\n","        if self.scaler or self.extract_datetime:\n","            df = Adjust(self.scaler, self.extract_datetime).handle(df)\n","        if self.encode_categ:\n","            df = EncodeCateg(self.encode_categ).handle(df)\n","\n","        for col in df.columns:\n","            if original_dtypes[col] in [np.float64, np.int64]:\n","                df[col] = df[col].astype(original_dtypes[col])\n","\n","        return df\n","\n","\n","class Duplicates:\n","    def handle(self, df):\n","        df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","\n","class MissingValues:\n","    def __init__(self, missing_num=None, missing_categ=None):\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","\n","    def handle(self, df, _n_neighbors=5):\n","        if self.missing_num or self.missing_categ:\n","            if df.isna().sum().sum() != 0:\n","                if self.missing_num:\n","                    df = self._handle_missing_num(df, _n_neighbors)\n","                if self.missing_categ:\n","                    df = self._handle_missing_categ(df, _n_neighbors)\n","        return df\n","\n","    def _handle_missing_num(self, df, _n_neighbors):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        for col in num_cols:\n","            if self.missing_num in ['auto', 'knn']:\n","                imputer = KNNImputer(n_neighbors=_n_neighbors)\n","                df[col] = imputer.fit_transform(df[[col]])\n","                df[col] = df[col].round().astype('Int64')\n","        return df\n","\n","    def _handle_missing_categ(self, df, _n_neighbors):\n","        cat_cols = set(df.columns) - set(df.select_dtypes(include=np.number).columns)\n","        for col in cat_cols:\n","            if self.missing_categ in ['auto', 'logreg', 'most_frequent']:\n","                if self.missing_categ == 'most_frequent':\n","                    strategy = self.missing_categ\n","                else:\n","                    strategy = 'constant'\n","                imputer = SimpleImputer(strategy=strategy)\n","                df[col] = imputer.fit_transform(df[[col]])\n","        return df\n","\n","\n","class Outliers:\n","    def handle(self, df):\n","        df = self.replace_outliers(df)\n","        return df\n","\n","    def detect_outliers(self, df):\n","        Q1 = df.quantile(0.25)\n","        Q3 = df.quantile(0.75)\n","        IQR = Q3 - Q1\n","        return ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n","\n","    def replace_outliers(self, df, replacement_value=None):\n","        if replacement_value is None:\n","            replacement_value = df.median(numeric_only=True)\n","        for col in df.columns:\n","            if df[col].dtype != 'O':\n","                Q1 = df[col].quantile(0.25)\n","                Q3 = df[col].quantile(0.75)\n","                IQR = Q3 - Q1\n","                lower_bound = Q1 - 1.5 * IQR\n","                upper_bound = Q3 + 1.5 * IQR\n","                df[col] = np.where((df[col] < lower_bound) | (df[col] > upper_bound), replacement_value[col], df[col])\n","        return df\n","\n","\n","class Adjust:\n","    def __init__(self, scaler=None, extract_datetime=False):\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","\n","    def handle(self, df):\n","        if self.scaler or self.extract_datetime:\n","            df = self._convert_datetime(df)\n","            if self.scaler:\n","                if self.scaler in ['MinMax', 'Standard', 'Robust']:\n","                    scaler = preprocessing.__getattribute__(self.scaler+'Scaler')()\n","                    df[df.columns] = scaler.fit_transform(df[df.columns])\n","        return df\n","\n","    def _convert_datetime(self, df):\n","        cols = set(df.columns) & set(self.extract_datetime)\n","        for col in cols:\n","            try:\n","                df[col] = pd.to_datetime(df[col], errors='coerce')\n","                if self.extract_datetime:\n","                    df[col + '_year'] = df[col].dt.year\n","                    df[col + '_month'] = df[col].dt.month\n","                    df[col + '_day'] = df[col].dt.day\n","                    df.drop(columns=[col], inplace=True)\n","            except:\n","                pass\n","        return df\n","\n","\n","class EncodeCateg:\n","    def __init__(self, encode_categ=None):\n","        self.encode_categ = encode_categ\n","\n","    def handle(self, df):\n","        if self.encode_categ:\n","            if self.encode_categ == 'auto':\n","                self._auto_encode(df)\n","            elif isinstance(self.encode_categ, list):\n","                for col in self.encode_categ:\n","                    if col in df.columns:\n","                        self._auto_encode(df, col)\n","        return df\n","\n","    def _auto_encode(self, df, col=None):\n","        if col:\n","            if df[col].dtype == 'O':\n","                if len(df[col].unique()) <= 10:\n","                    df[col] = df[col].astype('category')\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col], drop_first=True)\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        else:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df[col] = df[col].astype('category')\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col], drop_first=True)\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df"],"metadata":{"cellView":"form","id":"usbzIBiPCYay"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv(\"loan_data.csv\")\n","print('original data info :')\n","print(data.info())\n","def detect_outliers_iqr(data):\n","    outliers = pd.DataFrame()\n","    for column in data.columns:\n","        if data[column].dtype in ['int64', 'float64']:  # Check if column is numerical\n","            q1 = data[column].quantile(0.25)\n","            q3 = data[column].quantile(0.75)\n","            iqr = q3 - q1\n","            lower_bound = q1 - 1.5 * iqr\n","            upper_bound = q3 + 1.5 * iqr\n","            column_outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)][column]\n","            outliers = pd.concat([outliers, column_outliers], axis=1)\n","    return outliers\n","\n","outliers = detect_outliers_iqr(data)\n","print()\n","print('Outliers in original dataset :')\n","print(outliers.any())"],"metadata":{"id":"KcAeUxmSCYdz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709614337771,"user_tz":-330,"elapsed":461,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"7a4cee37-95e5-4926-aaa4-743989bc5ccb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["original data info :\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4587 entries, 0 to 4586\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ApplicantIncome    4157 non-null   float64\n"," 1   CoapplicantIncome  4587 non-null   float64\n"," 2   LoanAmount         4145 non-null   float64\n"," 3   Loan_Amount_Term   4587 non-null   int64  \n"," 4   Credit_History     4587 non-null   int64  \n"," 5   Education          4587 non-null   object \n"," 6   Property_Area      4587 non-null   object \n"," 7   Loan_Status        4587 non-null   object \n","dtypes: float64(3), int64(2), object(3)\n","memory usage: 286.8+ KB\n","None\n","\n","Outliers in original dataset :\n","ApplicantIncome       True\n","CoapplicantIncome     True\n","LoanAmount            True\n","Loan_Amount_Term     False\n","Credit_History       False\n","dtype: bool\n"]}]},{"cell_type":"code","source":["clean_data = DataCleaning(duplicates=True,missing_num='knn',missing_categ='most_frequent',outliers_method=True,\n","                                scaler='minMax',extract_datetime='year',encode_categ='auto')"],"metadata":{"id":"fA9UIKdA8sE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cleaned_data = clean_data.fit_transform(data)\n","print('cleaned data info :')\n","print(cleaned_data.info())\n","\n","def detect_outliers_iqr(data):\n","    outliers = pd.DataFrame()\n","    for column in data.columns:\n","        if data[column].dtype in ['int64', 'float64']:\n","            q1 = data[column].quantile(0.25)\n","            q3 = data[column].quantile(0.75)\n","            iqr = q3 - q1\n","            lower_bound = q1 - 1.5 * iqr\n","            upper_bound = q3 + 1.5 * iqr\n","            column_outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)][column]\n","            outliers = pd.concat([outliers, column_outliers], axis=1)\n","    return outliers\n","\n","outliers = detect_outliers_iqr(cleaned_data)\n","print()\n","print('Outliers in cleaned dataset :')\n","print(outliers.any())"],"metadata":{"id":"H9G1iRceCYhI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709614285567,"user_tz":-330,"elapsed":12,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"4756bd27-3f25-4cb0-dbea-9f760bcfff91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cleaned data info :\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4587 entries, 0 to 4586\n","Data columns (total 8 columns):\n"," #   Column             Non-Null Count  Dtype  \n","---  ------             --------------  -----  \n"," 0   ApplicantIncome    4587 non-null   float64\n"," 1   CoapplicantIncome  4587 non-null   float64\n"," 2   LoanAmount         4587 non-null   float64\n"," 3   Loan_Amount_Term   4587 non-null   int64  \n"," 4   Credit_History     4587 non-null   int64  \n"," 5   Education          4587 non-null   object \n"," 6   Property_Area      4587 non-null   object \n"," 7   Loan_Status        4587 non-null   object \n","dtypes: float64(3), int64(2), object(3)\n","memory usage: 286.8+ KB\n","None\n","\n","Outliers in cleaned dataset :\n","ApplicantIncome      False\n","CoapplicantIncome    False\n","LoanAmount           False\n","Loan_Amount_Term     False\n","Credit_History       False\n","dtype: bool\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"cxYYnkNN2GY1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"po1hX5NJ2GVe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title HPO-GridSearch\n","from sklearn.model_selection import cross_val_score\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.svm import SVR, SVC\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import mean_squared_error, accuracy_score\n","\n","################################################################################\n","\n","#Decision Tree HPO\n","#Decision Tree Regressor\n","dt_regressor_params = {\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","dt_regressor = DecisionTreeRegressor(random_state=0)\n","grid_regressor = GridSearchCV(dt_regressor, dt_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X, y)\n","\n","print(\"Decision Tree Regressor Best Parameters:\")\n","print(grid_regressor.best_params_)\n","print(\"MSE:\"+ str(-grid_regressor.best_score_))\n","\n","#Decision Tree Classifier\n","dt_classifier_params = {\n","    'max_depth': [None, 5, 10, 15],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","dt_classifier = DecisionTreeClassifier(random_state=0)\n","grid_classifier = GridSearchCV(dt_classifier, dt_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X, y)\n","\n","print(\"\\nDecision Tree Classifier Best Parameters:\")\n","print(grid_classifier.best_params_)\n","print(\"Accuracy:\"+ str(grid_classifier.best_score_))\n","\n","################################################################################\n","\n","#Random Forest HPO\n","#Random Forest Regressor\n","rf_regressor_params = {\n","    'n_estimators': [10, 20, 30],\n","    'max_depth': [15, 20, 30, 50],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    \"bootstrap\": [True, False],\n","    \"criterion\": ['mse', 'mae']\n","}\n","\n","rf_regressor = RandomForestRegressor(random_state=0)\n","grid_regressor = GridSearchCV(rf_regressor, rf_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X, y)\n","\n","print(\"Random Forest Regressor Best Parameters:\")\n","print(grid_regressor.best_params_)\n","print(\"MSE:\" + str(-grid_regressor.best_score_))\n","\n","#Random Forest Classifier\n","rf_classifier_params = {\n","    'n_estimators': [10, 20, 30],\n","    'max_depth': [15, 20, 30, 50],\n","    'min_samples_leaf': [1, 2, 4, 8],\n","    \"bootstrap\": [True, False],\n","    \"criterion\": ['gini', 'entropy']\n","}\n","\n","rf_classifier = RandomForestClassifier(random_state=0)\n","grid_classifier = GridSearchCV(rf_classifier, rf_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X, y)\n","\n","print(\"\\nRandom Forest Classifier Best Parameters:\")\n","print(grid_classifier.best_params_)\n","print(\"Accuracy:\" + str(grid_classifier.best_score_))\n","\n","################################################################################\n","\n","#Gradient Boost Machine HPO\n","#GBM Regressor\n","gbm_regressor_params = {\n","    'n_estimators': [50, 100, 150],\n","    'learning_rate': [0.05, 0.1, 0.2],\n","    'max_depth': [3, 4, 5],\n","    'min_samples_split': [2, 3, 4]\n","}\n","\n","gbm_regressor = GradientBoostingRegressor()\n","grid_regressor = GridSearchCV(gbm_regressor, gbm_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X, y)\n","\n","print(\"GBM Regressor Best Parameters:\")\n","print(grid_regressor.best_params_)\n","print(\"MSE:\" + str(-grid_regressor.best_score_))\n","\n","#GBM Classifier\n","gbm_classifier_params = {\n","    'n_estimators': [50, 100, 150],\n","    'learning_rate': [0.05, 0.1, 0.2],\n","    'max_depth': [3, 4, 5],\n","    'min_samples_split': [2, 3, 4],\n","    'subsample': [0.8, 0.9, 1.0]\n","}\n","\n","gbm_classifier = GradientBoostingClassifier()\n","grid_classifier = GridSearchCV(gbm_classifier, gbm_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X, y)\n","\n","print(\"\\nGBM Classifier Best Parameters:\")\n","print(grid_classifier.best_params_)\n","print(\"Accuracy:\" + str(grid_classifier.best_score_))\n","\n","################################################################################\n","\n","#Support Vector Machine HPO\n","#SVM Regressor\n","svm_regressor_params = {\n","    'kernel': ['linear', 'poly', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'epsilon': [0.1, 0.2, 0.5]\n","}\n","\n","svm_regressor = SVR()\n","grid_regressor = GridSearchCV(svm_regressor, svm_regressor_params, cv=3, scoring='neg_mean_squared_error')\n","grid_regressor.fit(X, y)\n","\n","print(\"SVM Regressor Best Parameters:\")\n","print(grid_regressor.best_params_)\n","print(\"MSE:\" + str(-grid_regressor.best_score_))\n","\n","#SVM Classifier\n","svm_classifier_params = {\n","    'kernel': ['linear', 'poly', 'rbf'],\n","    'C': [0.1, 1, 10],\n","    'gamma': ['scale', 'auto'],\n","    'class_weight': ['balanced', None]\n","}\n","\n","svm_classifier = SVC()\n","grid_classifier = GridSearchCV(svm_classifier, svm_classifier_params, cv=3, scoring='accuracy')\n","grid_classifier.fit(X, y)\n","\n","print(\"\\nSVM Classifier Best Parameters:\")\n","print(grid_classifier.best_params_)\n","print(\"Accuracy:\" + str(grid_classifier.best_score_))\n","\n","################################################################################"],"metadata":{"id":"yaPednLMFuYU","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title HPO-skopt\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.svm import SVR, SVC\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from skopt import BayesSearchCV\n","from skopt.space import Real, Integer, Categorical\n","\n","################################################################################\n","\n","#Decision Tree HPO\n","#Hyperparameter tuning for Decision Tree Regressor\n","dtr_params = {\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'criterion': Categorical(['mse', 'mae'])\n","}\n","\n","dtr = DecisionTreeRegressor(random_state=42)\n","bayes_dtr = BayesSearchCV(dtr, dtr_params, n_iter=20, cv=3, scoring='neg_mean_squared_error', random_state=42)\n","bayes_dtr.fit(x, y)\n","\n","print(\"Decision Tree Regressor: Best parameters -\", bayes_dtr.best_params_)\n","print(\"Negative Mean Squared Error:\", -bayes_dtr.best_score_)\n","\n","#Hyperparameter tuning for Decision Tree Classifier\n","dtc_params = {\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'criterion': Categorical(['gini', 'entropy'])\n","}\n","\n","dtc = DecisionTreeClassifier(random_state=42)\n","bayes_dtc = BayesSearchCV(dtc, dtc_params, n_iter=20, cv=3, scoring='accuracy', random_state=42)\n","bayes_dtc.fit(x, y)\n","\n","print(\"Decision Tree Classifier: Best parameters -\", bayes_dtc.best_params_)\n","print(\"Accuracy:\", bayes_dtc.best_score_)\n","\n","################################################################################\n","\n","#Random Forest HPO\n","#Hyperparameter tuning for Random Forest Regressor\n","rfr_params = {\n","    'n_estimators': Integer(10, 100),\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'criterion': Categorical(['mse', 'mae'])\n","}\n","\n","rfr = RandomForestRegressor(random_state=42)\n","bayes_rfr = BayesSearchCV(rfr, rfr_params, n_iter=20, cv=3, scoring='neg_mean_squared_error', random_state=42)\n","bayes_rfr.fit(X, y)\n","\n","print(\"Random Forest Regressor: Best parameters -\", bayes_rfr.best_params_)\n","print(\"Negative Mean Squared Error:\", -bayes_rfr.best_score_)\n","\n","#Hyperparameter tuning for Random Forest Classifier\n","rfc_params = {\n","    'n_estimators': Integer(10, 100),\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'criterion': Categorical(['gini', 'entropy'])\n","}\n","\n","rfc = RandomForestClassifier(random_state=42)\n","bayes_rfc = BayesSearchCV(rfc, rfc_params, n_iter=20, cv=3, scoring='accuracy', random_state=42)\n","bayes_rfc.fit(X, y)\n","\n","print(\"Random Forest Classifier: Best parameters -\", bayes_rfc.best_params_)\n","print(\"Accuracy:\", bayes_rfc.best_score_)\n","\n","################################################################################\n","\n","#Gradient Boost Machine HPO\n","#Hyperparameter tuning for GBM Regressor\n","gbr_params = {\n","    'n_estimators': Integer(10, 100),\n","    'learning_rate': Real(0.001, 1.0, 'log-uniform'),\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'subsample': Real(0.1, 1.0, 'uniform')\n","}\n","\n","gbr = GradientBoostingRegressor(random_state=42)\n","bayes_gbr = BayesSearchCV(gbr, gbr_params, n_iter=20, cv=3, scoring='neg_mean_squared_error', random_state=42)\n","bayes_gbr.fit(X, y)\n","\n","print(\"GBM Regressor: Best parameters -\", bayes_gbr.best_params_)\n","print(\"Negative Mean Squared Error:\", -bayes_gbr.best_score_)\n","\n","#Hyperparameter tuning for GBM Classifier\n","gbc_params = {\n","    'n_estimators': Integer(10, 100),\n","    'learning_rate': Real(0.001, 1.0, 'log-uniform'),\n","    'max_depth': Integer(1, 50),\n","    'min_samples_split': Integer(2, 20),\n","    'min_samples_leaf': Integer(1, 20),\n","    'subsample': Real(0.1, 1.0, 'uniform')\n","}\n","\n","gbc = GradientBoostingClassifier(random_state=42)\n","bayes_gbc = BayesSearchCV(gbc, gbc_params, n_iter=20, cv=3, scoring='accuracy', random_state=42)\n","bayes_gbc.fit(X, y)\n","\n","print(\"GBM Classifier: Best parameters -\", bayes_gbc.best_params_)\n","print(\"Accuracy:\", bayes_gbc.best_score_)\n","\n","################################################################################\n","\n","#Support Vector Machine HPO\n","#Hyperparameter tuning for SVM Regressor\n","svr_params = {\n","    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n","    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n","    'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n","    'epsilon': Real(1e-6, 1e+1, prior='log-uniform')\n","}\n","\n","svr = SVR()\n","bayes_svr = BayesSearchCV(svr, svr_params, n_iter=20, cv=3, scoring='neg_mean_squared_error', random_state=42)\n","bayes_svr.fit(X, y)\n","\n","print(\"SVM Regressor: Best parameters -\", bayes_svr.best_params_)\n","print(\"Negative Mean Squared Error:\", -bayes_svr.best_score_)\n","\n","#Hyperparameter tuning for SVM Classifier\n","svc_params = {\n","    'C': Real(1e-6, 1e+6, prior='log-uniform'),\n","    'kernel': Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n","    'gamma': Real(1e-6, 1e+1, prior='log-uniform')\n","}\n","\n","svc = SVC()\n","bayes_svc = BayesSearchCV(svc, svc_params, n_iter=20, cv=3, scoring='accuracy', random_state=42)\n","bayes_svc.fit(X, y)\n","\n","print(\"SVM Classifier: Best parameters -\", bayes_svc.best_params_)\n","print(\"Accuracy:\", bayes_svc.best_score_)\n","\n","################################################################################"],"metadata":{"cellView":"form","id":"yJvbe_hvFuST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title HPO-BayesianOptimization\n","from sklearn.model_selection import cross_val_score\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.svm import SVR, SVC\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from bayes_opt import BayesianOptimization\n","\n","################################################################################\n","\n","# Decision Tree HPO\n","# Hyperparameter tuning for Decision Tree Regressor\n","def optimize_dtr(max_depth, min_samples_split, min_samples_leaf, criterion):\n","    dtr = DecisionTreeRegressor(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                 min_samples_leaf=int(min_samples_leaf), criterion=criterion)\n","    return -cross_val_score(dtr, X, y, cv=3, scoring='neg_mean_squared_error').mean()\n","\n","dtr_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","              'min_samples_leaf': (1, 20), 'criterion': ['mse', 'mae']}\n","\n","bayes_dtr = BayesianOptimization(f=optimize_dtr, pbounds=dtr_bounds, random_state=42)\n","bayes_dtr.maximize(init_points=10, n_iter=10)\n","\n","print(\"Decision Tree Regressor: Best parameters -\", bayes_dtr.max)\n","print(\"Negative Mean Squared Error:\", -bayes_dtr.max['target'])\n","\n","# Hyperparameter tuning for Decision Tree Classifier\n","def optimize_dtc(max_depth, min_samples_split, min_samples_leaf, criterion):\n","    dtc = DecisionTreeClassifier(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                  min_samples_leaf=int(min_samples_leaf), criterion=criterion)\n","    return cross_val_score(dtc, X, y, cv=3, scoring='accuracy').mean()\n","\n","dtc_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","              'min_samples_leaf': (1, 20), 'criterion': ['gini', 'entropy']}\n","\n","bayes_dtc = BayesianOptimization(f=optimize_dtc, pbounds=dtc_bounds, random_state=42)\n","bayes_dtc.maximize(init_points=10, n_iter=10)\n","\n","print(\"Decision Tree Classifier: Best parameters -\", bayes_dtc.max)\n","print(\"Accuracy:\", bayes_dtc.max['target'])\n","\n","################################################################################\n","\n","# Random Forest HPO\n","# Hyperparameter tuning for Random Forest Regressor\n","def optimize_rfr(n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion):\n","    rfr = RandomForestRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth),\n","                                 min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf),\n","                                 criterion=criterion)\n","    return -cross_val_score(rfr, X, y, cv=3, scoring='neg_mean_squared_error').mean()\n","\n","rfr_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","              'min_samples_leaf': (1, 20), 'criterion': ['mse', 'mae']}\n","\n","bayes_rfr = BayesianOptimization(f=optimize_rfr, pbounds=rfr_bounds, random_state=42)\n","bayes_rfr.maximize(init_points=10, n_iter=10)\n","\n","print(\"Random Forest Regressor: Best parameters -\", bayes_rfr.max)\n","print(\"Negative Mean Squared Error:\", -bayes_rfr.max['target'])\n","\n","# Hyperparameter tuning for Random Forest Classifier\n","def optimize_rfc(n_estimators, max_depth, min_samples_split, min_samples_leaf, criterion):\n","    rfc = RandomForestClassifier(n_estimators=int(n_estimators), max_depth=int(max_depth),\n","                                  min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf),\n","                                  criterion=criterion)\n","    return cross_val_score(rfc, X, y, cv=3, scoring='accuracy').mean()\n","\n","rfc_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","              'min_samples_leaf': (1, 20), 'criterion': ['gini', 'entropy']}\n","\n","bayes_rfc = BayesianOptimization(f=optimize_rfc, pbounds=rfc_bounds, random_state=42)\n","bayes_rfc.maximize(init_points=10, n_iter=10)\n","\n","print(\"Random Forest Classifier: Best parameters -\", bayes_rfc.max)\n","print(\"Accuracy:\", bayes_rfc.max['target'])\n","\n","################################################################################\n","\n","# Gradient Boost Machine HPO\n","# Hyperparameter tuning for GBM Regressor\n","def optimize_gbr(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","    gbr = GradientBoostingRegressor(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","                                     max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                     min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","    return -cross_val_score(gbr, X, y, cv=3, scoring='neg_mean_squared_error').mean()\n","\n","gbr_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","              'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","bayes_gbr = BayesianOptimization(f=optimize_gbr, pbounds=gbr_bounds, random_state=42)\n","bayes_gbr.maximize(init_points=10, n_iter=10)\n","\n","print(\"GBM Regressor: Best parameters -\", bayes_gbr.max)\n","print(\"Negative Mean Squared Error:\", -bayes_gbr.max['target'])\n","\n","# Hyperparameter tuning for GBM Classifier\n","def optimize_gbc(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","    gbc = GradientBoostingClassifier(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","                                     max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","                                     min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","    return cross_val_score(gbc, X, y, cv=3, scoring='accuracy').mean()\n","\n","gbc_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","              'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","bayes_gbc = BayesianOptimization(f=optimize_gbc, pbounds=gbc_bounds, random_state=42)\n","bayes_gbc.maximize(init_points=10, n_iter=10)\n","\n","print(\"GBM Classifier: Best parameters -\", bayes_gbc.max)\n","print(\"Accuracy:\", bayes_gbc.max['target'])\n","\n","################################################################################\n","\n","# Support Vector Machine HPO\n","# Hyperparameter tuning for SVM Regressor\n","def optimize_svr(C, kernel, gamma, epsilon):\n","    svr = SVR(C=C, kernel=kernel, gamma=gamma, epsilon=epsilon)\n","    return -cross_val_score(svr, X, y, cv=3, scoring='neg_mean_squared_error').mean()\n","\n","svr_bounds = {'C': (1e-6, 1e+6), 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","              'gamma': (1e-6, 1e+1), 'epsilon': (1e-6, 1e+1)}\n","\n","bayes_svr = BayesianOptimization(f=optimize_svr, pbounds=svr_bounds, random_state=42)\n","bayes_svr.maximize(init_points=10, n_iter=10)\n","\n","print(\"SVM Regressor: Best parameters -\", bayes_svr.max)\n","print(\"Negative Mean Squared Error:\", -bayes_svr.max['target'])\n","\n","# Hyperparameter tuning for SVM Classifier\n","def optimize_svc(C, kernel, gamma):\n","    svc = SVC(C=C, kernel=kernel, gamma=gamma)\n","    return cross_val_score(svc, X, y, cv=3, scoring='accuracy').mean()\n","\n","svc_bounds = {'C': (1e-6, 1e+6), 'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'gamma': (1e-6, 1e+1)}\n","\n","bayes_svc = BayesianOptimization(f=optimize_svc, pbounds=svc_bounds, random_state=42)\n","bayes_svc.maximize(init_points=10, n_iter=10)\n","\n","print(\"SVM Classifier: Best parameters -\", bayes_svc.max)\n","print(\"Accuracy:\", bayes_svc.max['target'])\n","\n","################################################################################"],"metadata":{"cellView":"form","id":"koUOzpwaFuU-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"px6F0jYt2Q4n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MPeQnuRe2Q1R"},"execution_count":null,"outputs":[]}]}