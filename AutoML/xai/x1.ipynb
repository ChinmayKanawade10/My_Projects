{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN+pyVmWaptNcCH6r11taUg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install bayesian-optimization\n","!pip install shap lime"],"metadata":{"id":"SwEmzMPRBlA3","executionInfo":{"status":"ok","timestamp":1712836122543,"user_tz":-330,"elapsed":17768,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"885b284c-566a-42a9-f76c-6fc34422f9da"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bayesian-optimization\n","  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n","Collecting colorama>=0.4.6 (from bayesian-optimization)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.4.0)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n","Collecting shap\n","  Downloading shap-0.45.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (538 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m538.2/538.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.25.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.0.3)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.2)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.0)\n","Collecting slicer==0.0.7 (from shap)\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.2.12)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.4.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.50.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=f35cdaddc9cf943fb0a0f4e35bb99c9e3591a3175048f08983b232ce546230b6\n","  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n","Successfully built lime\n","Installing collected packages: slicer, shap, lime\n","Successfully installed lime-0.2.0.1 shap-0.45.0 slicer-0.0.7\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from scipy.stats import skew\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from sklearn.metrics import r2_score, accuracy_score\n","from bayes_opt import BayesianOptimization\n","import shap\n","import lime , lime.lime_tabular"],"metadata":{"id":"EwByfk9L9utY","executionInfo":{"status":"ok","timestamp":1712836128674,"user_tz":-330,"elapsed":3964,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["#@title Preprocessing database\n","\n","irrelevant_columns = [\n","    \"ID\", \"id\", \"Index\", \"index\", \"Serial Number\", \"serial_number\",\n","    \"Address\", \"address\", \"Href\", \"href\", \"Timestamp\", \"timestamp\",\n","    \"Creation Date\", \"creation_date\", \"Last Updated Date\", \"last_updated_date\",\n","    \"Version\", \"version\", \"Checksum\", \"checksum\", \"Year\", \"year\"\n","    \"Row ID\", \"row_id\", \"Record ID\", \"record_id\", \"Customer ID\", \"customer_id\",\n","    \"Client ID\", \"client_id\", \"Account ID\", \"account_id\", \"Transaction ID\", \"transaction_id\",\n","    \"Email\", \"email\", \"Phone Number\", \"phone_number\", \"Website\", \"website\",\n","    \"Fax\", \"fax\", \"IP Address\", \"ip_address\", \"MAC Address\", \"mac_address\",\n","    \"Social Security Number\", \"social_security_number\", \"Driver's License\", \"drivers_license\",\n","    \"ID_\", \"id_\", \"Index_\", \"index_\", \"Serial_Number\", \"serial_number_\",\n","    \"Address_\", \"address_\", \"Href_\", \"href_\", \"Timestamp_\", \"timestamp_\",\n","    \"Creation_Date\", \"creation_date_\", \"Last_Updated_Date\", \"last_updated_date_\",\n","    \"Version_\", \"version_\", \"Checksum_\", \"checksum_\",\n","    \"Row_ID\", \"row_id_\", \"Record_ID\", \"record_id_\", \"Customer_ID\", \"customer_id_\",\n","    \"Client_ID\", \"client_id_\", \"Account_ID\", \"account_id_\", \"Transaction_ID\", \"transaction_id_\",\n","    \"Email_\", \"email_\", \"Phone_Number\", \"phone_number_\", \"Website_\", \"website_\",\n","    \"Fax_\", \"fax_\", \"IP_Address\", \"ip_address_\", \"MAC_Address\", \"mac_address_\",\n","    \"Social_Security_Number\", \"social_security_number_\", \"Driver's_License\", \"drivers_license_\"\n","]\n","\n","ordinal_data = {\n","    'low':1,\n","    'medium':2,\n","    'moderate':2,\n","    'high':3,\n","    # Education Level\n","    'high school diploma': 1,\n","    'associate\\'s degree': 2,\n","    'bachelor\\'s degree': 3,\n","    'master\\'s degree': 4,\n","    'doctorate degree': 5,\n","    # Income Level\n","    'low income': 1,\n","    'middle income': 2,\n","    'high income': 3,\n","    # Customer Satisfaction\n","    'very dissatisfied': 1,\n","    'dissatisfied': 2,\n","    'neutral': 3,\n","    'satisfied': 4,\n","    'very satisfied': 5,\n","    # Likert Scale\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neither agree nor disagree': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Job Seniority\n","    'entry-level': 1,\n","    'mid-level': 2,\n","    'senior-level': 3,\n","    'executive-level': 4,\n","    # Severity of Illness/Condition\n","    'mild': 1,\n","    'moderate': 2,\n","    'severe': 3,\n","    # Temperature\n","    'cold': 1,\n","    'warm': 2,\n","    'hot': 3,\n","    'very hot': 4,\n","    # Customer Rating\n","    '1 star': 1,\n","    '2 stars': 2,\n","    '3 stars': 3,\n","    '4 stars': 4,\n","    '5 stars': 5,\n","    # Likelihood of Purchase\n","    'very unlikely': 1,\n","    'unlikely': 2,\n","    'likely': 4,\n","    'very likely': 5,\n","    # Degree of Agreement\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neutral': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Pain Scale\n","    'no pain': 1,\n","    'mild pain': 2,\n","    'moderate pain': 3,\n","    'severe pain': 4,\n","    'extreme pain': 5,\n","    # Likelihood of Recommendation\n","    'very unlikely to recommend': 1,\n","    'unlikely to recommend': 2,\n","    'likely to recommend': 4,\n","    'very likely to recommend': 5,\n","    # Quality Ratings\n","    'poor quality': 1,\n","    'fair quality': 2,\n","    'good quality': 3,\n","    'very good quality': 4,\n","    'excellent quality': 5,\n","    # Customer Service Experience\n","    'very poor': 1,\n","    'poor': 2,\n","    'average': 3,\n","    'good': 4,\n","    'excellent': 5,\n","    # Ease of Use\n","    'very difficult': 1,\n","    'difficult': 2,\n","    'easy': 4,\n","    'very easy': 5,\n","    # Likelihood of Churn\n","    'very unlikely to churn': 1,\n","    'unlikely to churn': 2,\n","    'likely to churn': 4,\n","    'very likely to churn': 5,\n","    # Satisfaction with Product/Service\n","    'not satisfied': 1,\n","    'slightly satisfied': 2,\n","    'moderately satisfied': 3,\n","    'extremely satisfied': 5,\n","    # Risk Levels\n","    'low risk': 1,\n","    'moderate risk': 2,\n","    'high risk': 3,\n","    # Performance Ratings\n","    'below expectations': 1,\n","    'meeting expectations': 2,\n","    'exceeding expectations': 3 }"],"metadata":{"cellView":"form","id":"LIV0ecZC9zKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data Preprocessing\n","\n","def remove_irrelevant_columns(data, irrelevant_columns):\n","  columns_to_delete = [col for col in data.columns if col in irrelevant_columns]\n","\n","  if len(columns_to_delete)>0:\n","    data.drop(columns=columns_to_delete, inplace=True)\n","\n","  return data\n","\n","\n","def remove_duplicate_values(data):\n","  if data.duplicated().any():\n","    data.drop_duplicates(inplace=True)\n","\n","  return data\n","\n","\n","def remove_constant_values(data):\n","  constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n","\n","  if len(constant_columns) > 0:\n","    data.drop(columns=constant_columns, inplace=True)\n","\n","  return data\n","\n","\n","def remove_string_numerical(data):\n","  string_num_cols = [col for col in data.columns if data[col].dtype == 'object' and data[col].str.isnumeric().all()]\n","\n","  if len(string_num_cols) > 0:\n","    data[string_num_cols] = data[string_num_cols].apply(pd.to_numeric)\n","\n","  return data\n","\n","\n","def remove_object_numerical(data):\n","  import re\n","  object_cols = data.select_dtypes(include=['object']).columns\n","\n","  if len(object_cols) > 0:\n","    for col in object_cols:\n","      numerical_values = data[col].apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+', str(x)))\n","      numeric_col = col + '_numeric'\n","      data[numeric_col] = numerical_values.apply(lambda x: float(x[0]) if x else None)\n","\n","  return data\n","\n","\n","def missing_values(data, threshold=0.5, k_neighbors=5):\n","  numerical_cols = data.select_dtypes(include=['number']).columns\n","  categorical_cols = data.select_dtypes(include=['object']).columns\n","\n","  if data.isnull().any().any():\n","      missing_percentage = data.isnull().mean()\n","\n","      if (missing_percentage > threshold).any():\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","        strategy = 'knn'\n","      else:\n","        imputer = SimpleImputer(strategy='mean')\n","        strategy = 'mean'\n","      if strategy == 'knn':\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","      else:\n","        imputer = SimpleImputer(strategy=strategy)\n","      data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n","      mode_imputer = SimpleImputer(strategy='most_frequent')\n","      data[categorical_cols] = mode_imputer.fit_transform(data[categorical_cols])\n","\n","  return data\n","\n","\n","# def convert_datetime(data):\n","#     object_cols = data.select_dtypes(include=['object']).columns\n","\n","#     if len(object_cols) > 0:\n","#         for col in object_cols:\n","#             try:\n","#                 data[col] = pd.to_datetime(data[col])\n","#                 data[col + '_numeric'] = data[col].astype('int64') // 10**9\n","#                 data.drop(columns=[col], inplace=True)\n","#             except (ValueError, TypeError):\n","#                 pass\n","\n","#     return data\n","\n","\n","def encode_objects(data):\n","  categorical_columns = data.select_dtypes(include=['object']).columns\n","\n","  if len(categorical_columns) > 0:\n","    for col in categorical_columns:\n","      unique_values_count = data[col].nunique()\n","\n","      if unique_values_count == 2:\n","        encoder = LabelEncoder()\n","        data[col] = encoder.fit_transform(data[col])\n","\n","      elif unique_values_count <= 7:\n","          if all(value in ordinal_data for value in data[col].str.lower()):\n","            data[col] = data[col].str.lower().map(ordinal_data)\n","          elif any(word in data[col].str.lower() for word in ['low', 'medium', 'moderate', 'high']):\n","            data[col] = data[col].apply(lambda x: ordinal_data[x.lower()] if x.lower() in ordinal_data else x)\n","          else:\n","            encoder = OneHotEncoder(sparse_output=False, drop='first')\n","            encoded_values = encoder.fit_transform(data[[col]])\n","            col_names = [f\"{col}_{value}\" for value in encoder.categories_[0][1:]]\n","            df = pd.DataFrame(encoded_values, columns=col_names)\n","            data = pd.concat([data, df], axis=1)\n","            data.drop(columns=[col], inplace=True)\n","\n","  return data\n","\n","\n","def adjust_values(data):\n","  scaler = StandardScaler()\n","  scaler.fit_transform(data)\n","\n","  return data\n","\n","\n","#master function\n","def automatic_data_preprocessing(data, threshold=0.5, k_neighbors=5):\n","\n","    data = remove_irrelevant_columns(data, irrelevant_columns)\n","    data = remove_duplicate_values(data)\n","    data = remove_constant_values(data)\n","    data = remove_string_numerical(data)\n","    data = remove_object_numerical(data)\n","    data = missing_values(data, threshold, k_neighbors)\n","    # data = convert_datetime(data)\n","    data = encode_objects(data)\n","    data = adjust_values(data)\n","\n","    return data"],"metadata":{"cellView":"form","id":"vuAO7LN89zH6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"metadata":{"id":"_v4WL8AD1Nno","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712836675099,"user_tz":-330,"elapsed":2560,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"99fa3451-4529-49e9-95f7-3f054e134fd0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Column Names with Indexes:\n","Index 0: mean_radius\n","Index 1: mean_texture\n","Index 2: mean_perimeter\n","Index 3: mean_area\n","Index 4: mean_smoothness\n","Index 5: diagnosis\n","Enter the index of the target variable column: 5\n","\n","X shape :  (569, 5)\n","y shape :  (569,)\n","X_train shape :  (455, 5)\n","X_test shape :  (114, 5)\n","y_train shape :  (455,)\n","y_test shape :  (114,)\n"]}],"source":["dataset = pd.read_csv('thyroid_cancer_data.csv')\n","# dataset = automatic_data_preprocessing(data)\n","\n","print(\"Column Names with Indexes:\")\n","for idx, col_name in enumerate(dataset.columns):\n","    print(f\"Index {idx}: {col_name}\")\n","target_col_idx = int(input(\"Enter the index of the target variable column: \"))\n","\n","X = dataset.drop(dataset.columns[target_col_idx], axis=1)\n","y = dataset.iloc[:, target_col_idx]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print()\n","print('X shape : ',X.shape)\n","print('y shape : ',y.shape)\n","print('X_train shape : ',X_train.shape)\n","print('X_test shape : ',X_test.shape)\n","print('y_train shape : ',y_train.shape)\n","print('y_test shape : ',y_test.shape)"]},{"cell_type":"code","source":["#@title Optimizer Functions\n","\n","# # Decision Tree Regressor Optimization\n","# def optimize_dtr(X_train, X_test, y_train, y_test):\n","#     def dtr_optimizer(max_depth, min_samples_split, min_samples_leaf):\n","#         dtr = DecisionTreeRegressor(max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                      min_samples_leaf=int(min_samples_leaf))\n","#         dtr.fit(X_train, y_train)\n","#         y_pred = dtr.predict(X_test)\n","#         return r2_score(y_test, y_pred), {'max_depth': int(max_depth),\n","#                                           'min_samples_split': int(min_samples_split),\n","#                                           'min_samples_leaf': int(min_samples_leaf)}\n","\n","#     dtr_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_dtr = BayesianOptimization(f=dtr_optimizer, pbounds=dtr_bounds, random_state=42)\n","#     bayes_dtr.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_dtr.max['params']\n","\n","#     dtr_final = DecisionTreeClassifier(max_depth=int(round(best_params['max_depth'])),\n","#                                        min_samples_split=int(best_params['min_samples_split']),\n","#                                        min_samples_leaf=int(best_params['min_samples_leaf']))\n","#     dtr_final.fit(X_train, y_train)\n","\n","#     y_pred = dtr_final.predict(X_test)\n","#     performance = r2_score(y_test, y_pred)\n","\n","#     return dtr_final, performance\n","\n","\n","# # Random Forest Regressor Optimization\n","# def optimize_rfr(X_train, X_test, y_train, y_test):\n","#     def rfr_optimizer(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","#         rfr = RandomForestRegressor(n_estimators=int(round(n_estimators)), max_depth=int(round(max_depth)),\n","#                                      min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","#         rfr.fit(X_train, y_train)\n","#         y_pred = rfr.predict(X_test)\n","#         return r2_score(y_test, y_pred)\n","\n","#     rfr_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_rfr = BayesianOptimization(f=rfr_optimizer, pbounds=rfr_bounds, random_state=42)\n","#     bayes_rfr.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_rfr.max['params']\n","\n","#     rfr_final = RandomForestRegressor(n_estimators=int(round(best_params['n_estimators'])),\n","#                                       max_depth=int(round(best_params['max_depth'])),\n","#                                       min_samples_split=int(best_params['min_samples_split']),\n","#                                       min_samples_leaf=int(best_params['min_samples_leaf']))\n","#     rfr_final.fit(X_train, y_train)\n","\n","#     y_pred = rfr_final.predict(X_test)\n","#     performance = r2_score(y_test, y_pred)\n","\n","#     return rfr_final, performance\n","\n","\n","# # Gradient Boosting Regressor Optimization\n","# def optimize_gbr(X_train, X_test, y_train, y_test):\n","#     def gbr_optimizer(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","#         gbr = GradientBoostingRegressor(n_estimators=int(round(n_estimators)), learning_rate=learning_rate,\n","#                                          max_depth=int(round(max_depth)), min_samples_split=int(min_samples_split),\n","#                                          min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","#         gbr.fit(X_train, y_train)\n","#         y_pred = gbr.predict(X_test)\n","#         return r2_score(y_test, y_pred)\n","\n","#     gbr_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","#                   'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","#     bayes_gbr = BayesianOptimization(f=gbr_optimizer, pbounds=gbr_bounds, random_state=42)\n","#     bayes_gbr.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_gbr.max['params']\n","\n","#     gbr_final = GradientBoostingRegressor(n_estimators=int(round(best_params['n_estimators'])),\n","#                                            learning_rate=best_params['learning_rate'],\n","#                                            max_depth=int(round(best_params['max_depth'])),\n","#                                            min_samples_split=int(best_params['min_samples_split']),\n","#                                            min_samples_leaf=int(best_params['min_samples_leaf']),\n","#                                            subsample=best_params['subsample'])\n","#     gbr_final.fit(X_train, y_train)\n","\n","#     y_pred = gbr_final.predict(X_test)\n","#     performance = r2_score(y_test, y_pred)\n","\n","#     return gbr_final, performance\n","\n","\n","# # Decision Tree Classifier Optimization\n","# def optimize_dtc(X_train, X_test, y_train, y_test):\n","#     def dtc_optimizer(max_depth, min_samples_split, min_samples_leaf):\n","#         dtc = DecisionTreeClassifier(max_depth=int(round(max_depth)), min_samples_split=int(min_samples_split),\n","#                                       min_samples_leaf=int(min_samples_leaf))\n","#         dtc.fit(X_train, y_train)\n","#         y_pred = dtc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred)\n","\n","#     dtc_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_dtc = BayesianOptimization(f=dtc_optimizer, pbounds=dtc_bounds, random_state=42)\n","#     bayes_dtc.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_dtc.max['params']\n","\n","#     dtc_final = DecisionTreeClassifier(max_depth=int(round(best_params['max_depth'])),\n","#                                        min_samples_split=int(best_params['min_samples_split']),\n","#                                        min_samples_leaf=int(best_params['min_samples_leaf']))\n","#     dtc_final.fit(X_train, y_train)\n","\n","#     y_pred = dtc_final.predict(X_test)\n","#     performance = accuracy_score(y_test, y_pred)\n","\n","#     return dtc_final, performance\n","\n","\n","# # Random Forest Classifier Optimization\n","# def optimize_rfc(X_train, X_test, y_train, y_test):\n","#     def rfc_optimizer(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","#         rfc = RandomForestClassifier(n_estimators=int(round(n_estimators)), max_depth=int(round(max_depth)),\n","#                                       min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","#         rfc.fit(X_train, y_train)\n","#         y_pred = rfc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred)\n","\n","#     rfc_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","#                   'min_samples_leaf': (1, 20)}\n","\n","#     bayes_rfc = BayesianOptimization(f=rfc_optimizer, pbounds=rfc_bounds, random_state=42)\n","#     bayes_rfc.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_rfc.max['params']\n","\n","#     rfc_final = RandomForestClassifier(n_estimators=int(round(best_params['n_estimators'])),\n","#                                        max_depth=int(round(best_params['max_depth'])),\n","#                                        min_samples_split=int(best_params['min_samples_split']),\n","#                                        min_samples_leaf=int(best_params['min_samples_leaf']))\n","#     rfc_final.fit(X_train, y_train)\n","\n","#     y_pred = rfc_final.predict(X_test)\n","#     performance = accuracy_score(y_test, y_pred)\n","\n","#     return rfc_final, performance\n","\n","\n","# # Gradient Boosting Classifier Optimization\n","# def optimize_gbc(X_train, X_test, y_train, y_test):\n","#     def gbc_optimizer(n_estimators, learning_rate, max_depth, min_samples_split, min_samples_leaf, subsample):\n","#         gbc = GradientBoostingClassifier(n_estimators=int(n_estimators), learning_rate=learning_rate,\n","#                                          max_depth=int(max_depth), min_samples_split=int(min_samples_split),\n","#                                          min_samples_leaf=int(min_samples_leaf), subsample=subsample)\n","#         gbc.fit(X_train, y_train)\n","#         y_pred = gbc.predict(X_test)\n","#         return accuracy_score(y_test, y_pred), {'n_estimators': int(n_estimators),\n","#                                                 'learning_rate': learning_rate,\n","#                                                 'max_depth': int(max_depth),\n","#                                                 'min_samples_split': int(min_samples_split),\n","#                                                 'min_samples_leaf': int(min_samples_leaf),\n","#                                                 'subsample': subsample}\n","\n","#     gbc_bounds = {'n_estimators': (10, 100), 'learning_rate': (0.001, 1.0), 'max_depth': (1, 50),\n","#                   'min_samples_split': (2, 20), 'min_samples_leaf': (1, 20), 'subsample': (0.1, 1.0)}\n","\n","#     bayes_gbc = BayesianOptimization(f=gbc_optimizer, pbounds=gbc_bounds, random_state=42)\n","#     bayes_gbc.maximize(init_points=10, n_iter=10)\n","#     best_params = bayes_gbc.max['params']\n","#     accuracy = bayes_gbc.max['target']\n","\n","#     gbc_final = GradientBoostingClassifier(n_estimators=int(round(best_params['n_estimators'])),\n","#                                            learning_rate=best_params['learning_rate'],\n","#                                            max_depth=int(round(best_params['max_depth'])),\n","#                                            min_samples_split=int(best_params['min_samples_split']),\n","#                                            min_samples_leaf=int(best_params['min_samples_leaf']),\n","#                                            subsample=best_params['subsample'])\n","#     gbc_final.fit(X_train, y_train)\n","\n","#     y_pred = gbc_final.predict(X_test)\n","#     performance = accuracy_score(y_test, y_pred)\n","\n","#     return gbc_final, performance"],"metadata":{"id":"VtRvXRD-CISN","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Decision Tree Classifier Optimization\n","def optimize_dtc(X_train, X_test, y_train, y_test):\n","    def dtc_optimizer(max_depth, min_samples_split, min_samples_leaf):\n","        dtc = DecisionTreeClassifier(max_depth=int(round(max_depth)), min_samples_split=int(min_samples_split),\n","                                      min_samples_leaf=int(min_samples_leaf))\n","        dtc.fit(X_train, y_train)\n","        y_pred = dtc.predict(X_test)\n","        return accuracy_score(y_test, y_pred)\n","\n","    dtc_bounds = {'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_dtc = BayesianOptimization(f=dtc_optimizer, pbounds=dtc_bounds, random_state=42)\n","    bayes_dtc.maximize(init_points=10, n_iter=10)\n","    params = bayes_dtc.max['params']\n","    return params"],"metadata":{"id":"Zfvoar36ZeVa","executionInfo":{"status":"ok","timestamp":1712836148553,"user_tz":-330,"elapsed":508,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["best_params = optimize_dtc(X_train, X_test, y_train, y_test)\n","model = DecisionTreeClassifier(max_depth=int(round(best_params['max_depth'])),\n","                                   min_samples_split=int(best_params['min_samples_split']),\n","                                   min_samples_leaf=int(best_params['min_samples_leaf']))\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","performance = accuracy_score(y_test, y_pred)\n","print(performance)"],"metadata":{"id":"Fpy1ceWd-Qf2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712836156683,"user_tz":-330,"elapsed":6311,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"3a4df722-6a3d-45b8-d253-0e50a0cd9fad"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["|   iter    |  target   | max_depth | min_sa... | min_sa... |\n","-------------------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m19.35    \u001b[0m | \u001b[0m19.06    \u001b[0m | \u001b[0m15.18    \u001b[0m |\n","| \u001b[0m2        \u001b[0m | \u001b[0m0.9123   \u001b[0m | \u001b[0m30.33    \u001b[0m | \u001b[0m3.964    \u001b[0m | \u001b[0m4.808    \u001b[0m |\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m3.846    \u001b[0m | \u001b[0m17.46    \u001b[0m | \u001b[0m12.82    \u001b[0m |\n","| \u001b[0m4        \u001b[0m | \u001b[0m0.9386   \u001b[0m | \u001b[0m35.7     \u001b[0m | \u001b[0m1.391    \u001b[0m | \u001b[0m19.46    \u001b[0m |\n","| \u001b[0m5        \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m41.79    \u001b[0m | \u001b[0m5.034    \u001b[0m | \u001b[0m5.273    \u001b[0m |\n","| \u001b[0m6        \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m9.987    \u001b[0m | \u001b[0m6.781    \u001b[0m | \u001b[0m11.45    \u001b[0m |\n","| \u001b[0m7        \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m22.17    \u001b[0m | \u001b[0m6.533    \u001b[0m | \u001b[0m13.01    \u001b[0m |\n","| \u001b[0m8        \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m7.835    \u001b[0m | \u001b[0m6.551    \u001b[0m | \u001b[0m8.595    \u001b[0m |\n","| \u001b[0m9        \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m23.35    \u001b[0m | \u001b[0m15.92    \u001b[0m | \u001b[0m5.594    \u001b[0m |\n","| \u001b[0m10       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m26.2     \u001b[0m | \u001b[0m12.26    \u001b[0m | \u001b[0m2.836    \u001b[0m |\n","| \u001b[0m11       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m9.809    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m19.64    \u001b[0m |\n","| \u001b[0m12       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m30.75    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m2.0      \u001b[0m |\n","| \u001b[0m13       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m12.61    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m2.0      \u001b[0m |\n","| \u001b[0m14       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m33.75    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m20.0     \u001b[0m |\n","| \u001b[0m15       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m20.0     \u001b[0m |\n","| \u001b[0m16       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m50.0     \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m5.632    \u001b[0m |\n","| \u001b[0m17       \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m1.229    \u001b[0m | \u001b[0m19.98    \u001b[0m | \u001b[0m3.99     \u001b[0m |\n","| \u001b[0m18       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m41.47    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m12.51    \u001b[0m |\n","| \u001b[0m19       \u001b[0m | \u001b[0m0.9211   \u001b[0m | \u001b[0m1.014    \u001b[0m | \u001b[0m19.65    \u001b[0m | \u001b[0m19.19    \u001b[0m |\n","| \u001b[0m20       \u001b[0m | \u001b[0m0.9561   \u001b[0m | \u001b[0m11.7     \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m11.73    \u001b[0m |\n","=============================================================\n","0.956140350877193\n"]}]},{"cell_type":"code","source":["explainer = shap.Explainer(model)\n","shap_values = explainer(X)\n","shap.plots.beeswarm(shap_values)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"id":"Gef1snZvAqnj","executionInfo":{"status":"error","timestamp":1712837178962,"user_tz":-330,"elapsed":7,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"015dcf09-d179-4da3-e270-9dc3592ba391"},"execution_count":21,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"The beeswarm plot does not support plotting explanations with instances that have more than one dimension!","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-7d3eea06238e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeeswarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/plots/_beeswarm.py\u001b[0m in \u001b[0;36mbeeswarm\u001b[0;34m(shap_values, max_display, order, clustering, cluster_threshold, color, axis_color, alpha, show, log_scale, color_bar, s, plot_size, color_bar_label)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;34m\"than one dimension!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         )\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mshap_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The beeswarm plot does not support plotting explanations with instances that have more than one dimension!"]}]}]}