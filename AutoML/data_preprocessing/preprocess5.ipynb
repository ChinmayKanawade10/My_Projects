{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM6SPsmpYRXbZQyuPV54roC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":47,"metadata":{"id":"9mQ7BZQmbX06","executionInfo":{"status":"ok","timestamp":1709579074509,"user_tz":-330,"elapsed":557,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.impute import KNNImputer, SimpleImputer\n","from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, LabelEncoder\n","from scipy.stats import zscore"]},{"cell_type":"code","source":["#@title preprocessing_classes\n","class Duplicates:\n","    def __init__(self, duplicates=True):\n","        self.duplicates = duplicates\n","\n","    def handle(self, df):\n","        if self.duplicates:\n","            df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","class MissingValues:\n","    def __init__(self, missing_num=None, missing_categ=None):\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","\n","    def handle(self, df, _n_neighbors=5):\n","        if self.missing_num or self.missing_categ:\n","            if df.isna().sum().sum() != 0:\n","                if self.missing_num:\n","                    df = self._handle_missing_num(df, _n_neighbors)\n","                if self.missing_categ:\n","                    df = self._handle_missing_categ(df, _n_neighbors)\n","        return df\n","\n","    def _handle_missing_num(self, df, _n_neighbors):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        for col in num_cols:\n","            if self.missing_num in ['auto', 'knn']:  # Use KNN imputation\n","                imputer = KNNImputer(n_neighbors=_n_neighbors)\n","                df[col] = imputer.fit_transform(df[[col]])\n","                df[col] = df[col].round().astype('Int64')\n","        return df\n","\n","    def _handle_missing_categ(self, df, _n_neighbors):\n","        cat_cols = set(df.columns) - set(df.select_dtypes(include=np.number).columns)\n","        for col in cat_cols:\n","            if self.missing_categ in ['auto', 'logreg', 'most_frequent']:\n","                if self.missing_categ == 'most_frequent':\n","                    strategy = self.missing_categ\n","                else:\n","                    strategy = 'constant'\n","                imputer = SimpleImputer(strategy=strategy)\n","                df[col] = imputer.fit_transform(df[[col]])\n","        return df\n","\n","class Outliers:\n","    def __init__(self, method=None, threshold=2.5):\n","        self.method = method\n","        self.threshold = threshold\n","\n","    def handle(self, df):\n","        if self.method == 'knn':  # Use KNN for imputation\n","            df = self._handle_knn(df)\n","        return df\n","\n","    def _handle_knn(self, df):\n","        imputer = KNNImputer()\n","        df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        # Identify outliers using z-score\n","        z_scores = np.abs(zscore(df_imputed))\n","        outlier_indices = np.any(z_scores > self.threshold, axis=1)\n","\n","        # If outliers are detected, apply a different imputation strategy\n","        if np.any(outlier_indices):\n","            df_outliers = df_imputed[outlier_indices]\n","            df_outliers.fillna(df_outliers.mean(), inplace=True)  # Replace NaNs with mean\n","            df_imputed.loc[outlier_indices] = df_outliers\n","\n","        return df_imputed\n","\n","\n","class Adjust:\n","    def __init__(self, scaler=None, extract_datetime=False):\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","\n","    def handle(self, df):\n","        if self.scaler:\n","            if self.scaler in ['minMax', 'standard', 'robust']:\n","                scaler = preprocessing.__getattribute__(self.scaler.capitalize()+'Scaler')()\n","                df[df.columns] = scaler.fit_transform(df[df.columns])\n","        if self.extract_datetime:\n","            df = self._convert_datetime(df)\n","        return df\n","\n","    def _convert_datetime(self, df):\n","        cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n","        for col in cols:\n","            try:\n","                df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","                if self.extract_datetime != False:\n","                    df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","            except:\n","                pass\n","        return df\n","\n","class EncodeCateg:\n","    def __init__(self, encode_categ=None):\n","        self.encode_categ = encode_categ\n","\n","    def handle(self, df):\n","        if self.encode_categ:\n","            if self.encode_categ == 'auto':\n","                self._auto_encode(df)\n","            elif isinstance(self.encode_categ, list):\n","                for col in self.encode_categ:\n","                    if col in df.columns:\n","                        self._auto_encode(df, col)\n","        return df\n","\n","    def _auto_encode(self, df, col=None):\n","        if col:\n","            if len(df[col].unique()) <= 10:\n","                df = pd.get_dummies(df, columns=[col], prefix=[col])\n","            else:\n","                le = LabelEncoder()\n","                df[col] = le.fit_transform(df[col])\n","        else:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col])\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df\n"],"metadata":{"id":"RQWpdZpTbZ-g","executionInfo":{"status":"ok","timestamp":1709579075539,"user_tz":-330,"elapsed":13,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["#@title master_class\n","class AutoDataCleaner:\n","    def __init__(self, duplicates=True, missing_strategy=None, outliers_method=None,\n","                 threshold=3, scaling_method=None, extract_datetime=False, encode_categorical=None):\n","        self.duplicates = duplicates\n","        self.missing_strategy = missing_strategy\n","        self.outliers_method = outliers_method\n","        self.threshold = threshold\n","        self.scaling_method = scaling_method\n","        self.extract_datetime = extract_datetime\n","        self.encode_categorical = encode_categorical\n","\n","    def fit_transform(self, df):\n","        if self.duplicates:\n","            df = self.remove_duplicates(df)\n","        if self.missing_strategy:\n","            df = self.handle_missing_values(df)\n","        if self.outliers_method:\n","            df = self.handle_outliers(df)\n","        if self.scaling_method:\n","            df = self.adjust_scaling(df)\n","        if self.extract_datetime:\n","            df = self.convert_datetime(df)\n","        if self.encode_categorical:\n","            df = self.encode_categorical_features(df)\n","        return df\n","\n","    def remove_duplicates(self, df):\n","        df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","    def handle_missing_values(self, df):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        cat_cols = df.select_dtypes(include='object').columns\n","\n","        if 'auto' in self.missing_strategy:\n","            df[num_cols] = self.impute_missing_values(df[num_cols], strategy='numeric')\n","            df[cat_cols] = self.impute_missing_values(df[cat_cols], strategy='categorical')\n","\n","        return df\n","\n","    def impute_missing_values(self, df, strategy='numeric'):\n","        imputer = None\n","        if 'knn' in self.missing_strategy:\n","            if strategy == 'numeric':\n","                imputer = KNNImputer()\n","            elif strategy == 'categorical':\n","                imputer = KNeighborsClassifier()\n","        elif 'most_frequent' in self.missing_strategy:\n","            imputer = SimpleImputer(strategy='most_frequent')\n","\n","        if imputer:\n","            df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        return df\n","\n","    def handle_outliers(self, df):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","\n","        if 'knn' in self.outliers_method:\n","            df = self.handle_outliers_knn(df[num_cols])\n","        else:\n","            df = self.remove_outliers(df[num_cols])\n","\n","        return df\n","\n","    def handle_outliers_knn(self, df):\n","        imputer = KNNImputer()\n","        df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        z_scores = np.abs(zscore(df_imputed))\n","        outlier_indices = np.any(z_scores > self.threshold, axis=1)\n","\n","        if np.any(outlier_indices):\n","            df_outliers = df_imputed[outlier_indices]\n","            df_outliers.fillna(df_outliers.mean(), inplace=True)\n","            df_imputed.loc[outlier_indices] = df_outliers\n","\n","        return df_imputed\n","\n","    def remove_outliers(self, df):\n","        if 'zscore' in self.outliers_method:\n","            z_scores = np.abs(zscore(df))\n","            df = df[(z_scores < self.threshold).all(axis=1)]\n","        elif 'iqr' in self.outliers_method:\n","            for col in df.columns:\n","                q1 = df[col].quantile(0.25)\n","                q3 = df[col].quantile(0.75)\n","                iqr = q3 - q1\n","                lower_bound = q1 - (self.threshold * iqr)\n","                upper_bound = q3 + (self.threshold * iqr)\n","                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","        return df\n","\n","    def adjust_scaling(self, df):\n","        scaler = None\n","        if 'minmax' in self.scaling_method:\n","            scaler = MinMaxScaler()\n","        elif 'standard' in self.scaling_method:\n","            scaler = StandardScaler()\n","        elif 'robust' in self.scaling_method:\n","            scaler = RobustScaler()\n","\n","        if scaler:\n","            df[df.columns] = scaler.fit_transform(df[df.columns])\n","        return df\n","\n","    def convert_datetime(self, df):\n","        cols = df.select_dtypes(include='datetime64').columns\n","        for col in cols:\n","            df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","            if self.extract_datetime != False:\n","                df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","\n","        return df\n","\n","    def encode_categorical_features(self, df):\n","        if 'auto' in self.encode_categorical:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col])\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df\n"],"metadata":{"cellView":"form","id":"fjOKCn6IbaA2","executionInfo":{"status":"ok","timestamp":1709579075539,"user_tz":-330,"elapsed":13,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":49,"outputs":[]}]}