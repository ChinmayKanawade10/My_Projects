{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxcKeb7jxJUdHLQ2JnH5mW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.pipeline import make_pipeline\n","from sklearn.impute import KNNImputer, SimpleImputer\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.linear_model import LinearRegression, LogisticRegression\n","from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler, LabelEncoder\n","from scipy.stats import zscore"],"metadata":{"id":"X9PViaIOH4t2","executionInfo":{"status":"ok","timestamp":1709571809841,"user_tz":-330,"elapsed":437,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":63,"outputs":[]},{"cell_type":"code","source":["#@title preprocessing_classes\n","# class Duplicates:\n","#     def __init__(self, duplicates=True):\n","#         self.duplicates = duplicates\n","\n","#     def handle(self, df):\n","#         if self.duplicates:\n","#             df.drop_duplicates(inplace=True, ignore_index=True)\n","#         return df\n","\n","# class MissingValues:\n","#     def __init__(self, missing_num=None, missing_categ=None):\n","#         self.missing_num = missing_num\n","#         self.missing_categ = missing_categ\n","\n","#     def handle(self, df, _n_neighbors=5):\n","#         if self.missing_num or self.missing_categ:\n","#             if df.isna().sum().sum() != 0:\n","#                 if self.missing_num:\n","#                     df = self._handle_missing_num(df, _n_neighbors)\n","#                 if self.missing_categ:\n","#                     df = self._handle_missing_categ(df, _n_neighbors)\n","#         return df\n","\n","#     def _handle_missing_num(self, df, _n_neighbors):\n","#         num_cols = df.select_dtypes(include=np.number).columns\n","#         for col in num_cols:\n","#             # if self.missing_num == 'delete':\n","#             #     df = df.dropna(subset=[col])\n","#             if self.missing_num in ['auto', 'knn']:  # Use KNN imputation\n","#                 imputer = KNNImputer(n_neighbors=_n_neighbors)\n","#                 df[col] = imputer.fit_transform(df[[col]])\n","#                 df[col] = df[col].round().astype('Int64')\n","#         return df\n","\n","#     def _handle_missing_categ(self, df, _n_neighbors):\n","#         cat_cols = set(df.columns) - set(df.select_dtypes(include=np.number).columns)\n","#         for col in cat_cols:\n","#             # if self.missing_categ == 'delete':\n","#             #     df = df.dropna(subset=[col])\n","#             if self.missing_categ in ['auto', 'logreg', 'most_frequent']:\n","#                 if self.missing_categ == 'most_frequent':\n","#                     strategy = self.missing_categ\n","#                 else:\n","#                     strategy = 'constant'\n","#                 imputer = SimpleImputer(strategy=strategy)\n","#                 df[col] = imputer.fit_transform(df[[col]])\n","#         return df\n","\n","# # class Outliers:\n","# #     def __init__(self, method=None, threshold=3):\n","# #         self.method = method\n","# #         self.threshold = threshold\n","\n","# #     def handle(self, df):\n","# #         if self.method:\n","# #             if self.method == 'zscore':\n","# #                 df = self._handle_zscore(df)\n","# #             elif self.method == 'iqr':\n","# #                 df = self._handle_iqr(df)\n","# #         return df\n","\n","# #     def _handle_zscore(self, df):\n","# #         num_cols = df.select_dtypes(include=np.number).columns\n","# #         for col in num_cols:\n","# #             z_scores = np.abs(zscore(df[col]))\n","# #             df = df[(z_scores < self.threshold).all(axis=1)]\n","# #         return df\n","\n","# #     def _handle_iqr(self, df):\n","# #         num_cols = df.select_dtypes(include=np.number).columns\n","# #         for col in num_cols:\n","# #             q1 = df[col].quantile(0.25)\n","# #             q3 = df[col].quantile(0.75)\n","# #             iqr = q3 - q1\n","# #             lower_bound = q1 - (self.threshold * iqr)\n","# #             upper_bound = q3 + (self.threshold * iqr)\n","# #             df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","# #         return df\n","# class Outliers:\n","#     def __init__(self, method=None, threshold=3):\n","#         self.method = method\n","#         self.threshold = threshold\n","\n","#     def handle(self, df):\n","#         if self.method == 'knn':  # Use KNN for imputation\n","#             df = self._handle_knn(df)\n","#         return df\n","\n","#     def _handle_knn(self, df):\n","#         imputer = KNNImputer()\n","#         df[df.columns] = imputer.fit_transform(df)\n","#         return df\n","\n","\n","# class Adjust:\n","#     def __init__(self, scaler=None, extract_datetime=False):\n","#         self.scaler = scaler\n","#         self.extract_datetime = extract_datetime\n","\n","#     def handle(self, df):\n","#         if self.scaler:\n","#             if self.scaler in ['minmax', 'standard', 'robust']:\n","#                 scaler = preprocessing.__getattribute__(self.scaler.capitalize()+'Scaler')()\n","#                 df[df.columns] = scaler.fit_transform(df[df.columns])\n","#         if self.extract_datetime:\n","#             df = self._convert_datetime(df)\n","#         return df\n","\n","#     def _convert_datetime(self, df):\n","#         cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n","#         for col in cols:\n","#             try:\n","#                 df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","#                 if self.extract_datetime != False:\n","#                     df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","#             except:\n","#                 pass\n","#         return df\n","\n","# class EncodeCateg:\n","#     def __init__(self, encode_categ=None):\n","#         self.encode_categ = encode_categ\n","\n","#     def handle(self, df):\n","#         if self.encode_categ:\n","#             if self.encode_categ == 'auto':\n","#                 self._auto_encode(df)\n","#             elif isinstance(self.encode_categ, list):\n","#                 for col in self.encode_categ:\n","#                     if col in df.columns:\n","#                         self._auto_encode(df, col)\n","#         return df\n","\n","#     def _auto_encode(self, df, col=None):\n","#         if col:\n","#             if len(df[col].unique()) <= 10:\n","#                 df = pd.get_dummies(df, columns=[col], prefix=[col])\n","#             else:\n","#                 le = LabelEncoder()\n","#                 df[col] = le.fit_transform(df[col])\n","#         else:\n","#             for col in df.select_dtypes(include='object'):\n","#                 if len(df[col].unique()) <= 10:\n","#                     df = pd.get_dummies(df, columns=[col], prefix=[col])\n","#                 else:\n","#                     le = LabelEncoder()\n","#                     df[col] = le.fit_transform(df[col])\n","#         return df\n","\n"],"metadata":{"cellView":"form","id":"fOOP5NcmKsMa","executionInfo":{"status":"ok","timestamp":1709570213907,"user_tz":-330,"elapsed":486,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["#@title master_class\n","# class AutoDataCleaner:\n","#     def __init__(self, duplicates=True, missing_strategy=None, outliers_method=None,\n","#                  threshold=3, scaling_method=None, extract_datetime=False, encode_categorical=None):\n","#         self.duplicates = duplicates\n","#         self.missing_strategy = missing_strategy\n","#         self.outliers_method = outliers_method\n","#         self.threshold = threshold\n","#         self.scaling_method = scaling_method\n","#         self.extract_datetime = extract_datetime\n","#         self.encode_categorical = encode_categorical\n","\n","#     def fit_transform(self, df):\n","#         if self.duplicates:\n","#             df = self.remove_duplicates(df)\n","#         if self.missing_strategy:\n","#             df = self.handle_missing_values(df)\n","#         if self.outliers_method:\n","#             df = self.handle_outliers(df)\n","#         if self.scaling_method:\n","#             df = self.adjust_scaling(df)\n","#         if self.extract_datetime:\n","#             df = self.convert_datetime(df)\n","#         if self.encode_categorical:\n","#             df = self.encode_categorical_features(df)\n","#         return df\n","\n","#     def remove_duplicates(self, df):\n","#         df.drop_duplicates(inplace=True, ignore_index=True)\n","#         return df\n","\n","#     def handle_missing_values(self, df):\n","#         num_cols = df.select_dtypes(include=np.number).columns\n","#         cat_cols = df.select_dtypes(include='object').columns\n","\n","#         # if 'delete' in self.missing_strategy:\n","#         #     df.dropna(subset=num_cols, inplace=True)\n","#         #     df.dropna(subset=cat_cols, inplace=True)\n","#         if 'auto' in self.missing_strategy:\n","#             df[num_cols] = self.impute_missing_values(df[num_cols], strategy='numeric')\n","#             df[cat_cols] = self.impute_missing_values(df[cat_cols], strategy='categorical')\n","\n","#         return df\n","\n","#     def impute_missing_values(self, df, strategy='numeric'):\n","#         imputer = None\n","#         if 'knn' in self.missing_strategy:\n","#             if strategy == 'numeric':\n","#                 imputer = KNeighborsRegressor()\n","#             elif strategy == 'categorical':\n","#                 imputer = KNeighborsClassifier()\n","#         elif 'most_frequent' in self.missing_strategy:\n","#             imputer = SimpleImputer(strategy='most_frequent')\n","\n","#         if imputer:\n","#             df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","#         return df\n","\n","#     def handle_outliers(self, df):\n","#         num_cols = df.select_dtypes(include=np.number).columns\n","\n","#         if 'zscore' in self.outliers_method:\n","#             df = self.remove_zscore_outliers(df[num_cols])\n","#         elif 'iqr' in self.outliers_method:\n","#             df = self.remove_iqr_outliers(df[num_cols])\n","\n","#         return df\n","\n","#     def remove_zscore_outliers(self, df):\n","#         z_scores = np.abs(zscore(df))\n","#         df = df[(z_scores < self.threshold).all(axis=1)]\n","#         return df\n","\n","#     def remove_iqr_outliers(self, df):\n","#         for col in df.columns:\n","#             q1 = df[col].quantile(0.25)\n","#             q3 = df[col].quantile(0.75)\n","#             iqr = q3 - q1\n","#             lower_bound = q1 - (self.threshold * iqr)\n","#             upper_bound = q3 + (self.threshold * iqr)\n","#             df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","#         return df\n","\n","#     def adjust_scaling(self, df):\n","#         scaler = None\n","#         if 'minmax' in self.scaling_method:\n","#             scaler = MinMaxScaler()\n","#         elif 'standard' in self.scaling_method:\n","#             scaler = StandardScaler()\n","#         elif 'robust' in self.scaling_method:\n","#             scaler = RobustScaler()\n","\n","#         if scaler:\n","#             df[df.columns] = scaler.fit_transform(df[df.columns])\n","#         return df\n","\n","#     def convert_datetime(self, df):\n","#         cols = df.select_dtypes(include='datetime64').columns\n","#         for col in cols:\n","#             df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","#             if self.extract_datetime != False:\n","#                 df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","\n","#         return df\n","\n","#     def encode_categorical_features(self, df):\n","#         if 'auto' in self.encode_categorical:\n","#             for col in df.select_dtypes(include='object'):\n","#                 if len(df[col].unique()) <= 10:\n","#                     df = pd.get_dummies(df, columns=[col], prefix=[col])\n","#                 else:\n","#                     le = LabelEncoder()\n","#                     df[col] = le.fit_transform(df[col])\n","#         return df\n"],"metadata":{"cellView":"form","id":"czqFif0UMKL9","executionInfo":{"status":"ok","timestamp":1709570215952,"user_tz":-330,"elapsed":536,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["#@title preprocessing_classes2\n","class Duplicates:\n","    def __init__(self, duplicates=True):\n","        self.duplicates = duplicates\n","\n","    def handle(self, df):\n","        if self.duplicates:\n","            df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","class MissingValues:\n","    def __init__(self, missing_num=None, missing_categ=None):\n","        self.missing_num = missing_num\n","        self.missing_categ = missing_categ\n","\n","    def handle(self, df, _n_neighbors=5):\n","        if self.missing_num or self.missing_categ:\n","            if df.isna().sum().sum() != 0:\n","                if self.missing_num:\n","                    df = self._handle_missing_num(df, _n_neighbors)\n","                if self.missing_categ:\n","                    df = self._handle_missing_categ(df, _n_neighbors)\n","        return df\n","\n","    def _handle_missing_num(self, df, _n_neighbors):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        for col in num_cols:\n","            if self.missing_num in ['auto', 'knn']:  # Use KNN imputation\n","                imputer = KNNImputer(n_neighbors=_n_neighbors)\n","                df[col] = imputer.fit_transform(df[[col]])\n","                df[col] = df[col].round().astype('Int64')\n","        return df\n","\n","    def _handle_missing_categ(self, df, _n_neighbors):\n","        cat_cols = set(df.columns) - set(df.select_dtypes(include=np.number).columns)\n","        for col in cat_cols:\n","            if self.missing_categ in ['auto', 'logreg', 'most_frequent']:\n","                if self.missing_categ == 'most_frequent':\n","                    strategy = self.missing_categ\n","                else:\n","                    strategy = 'constant'\n","                imputer = SimpleImputer(strategy=strategy)\n","                df[col] = imputer.fit_transform(df[[col]])\n","        return df\n","\n","class Outliers:\n","    def __init__(self, method=None, threshold=3):\n","        self.method = method\n","        self.threshold = threshold\n","\n","    def handle(self, df):\n","        if self.method == 'knn':  # Use KNN for imputation\n","            df = self._handle_knn(df)\n","        return df\n","\n","    def _handle_knn(self, df):\n","        imputer = KNNImputer()\n","        df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        # Identify outliers using z-score\n","        z_scores = np.abs(zscore(df_imputed))\n","        outlier_indices = np.any(z_scores > self.threshold, axis=1)\n","\n","        # If outliers are detected, apply a different imputation strategy\n","        if np.any(outlier_indices):\n","            df_outliers = df_imputed[outlier_indices]\n","            df_outliers.fillna(df_outliers.mean(), inplace=True)  # Replace NaNs with mean\n","            df_imputed.loc[outlier_indices] = df_outliers\n","\n","        return df_imputed\n","\n","\n","class Adjust:\n","    def __init__(self, scaler=None, extract_datetime=False):\n","        self.scaler = scaler\n","        self.extract_datetime = extract_datetime\n","\n","    def handle(self, df):\n","        if self.scaler:\n","            if self.scaler in ['minmax', 'standard', 'robust']:\n","                scaler = preprocessing.__getattribute__(self.scaler.capitalize()+'Scaler')()\n","                df[df.columns] = scaler.fit_transform(df[df.columns])\n","        if self.extract_datetime:\n","            df = self._convert_datetime(df)\n","        return df\n","\n","    def _convert_datetime(self, df):\n","        cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n","        for col in cols:\n","            try:\n","                df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","                if self.extract_datetime != False:\n","                    df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","            except:\n","                pass\n","        return df\n","\n","class EncodeCateg:\n","    def __init__(self, encode_categ=None):\n","        self.encode_categ = encode_categ\n","\n","    def handle(self, df):\n","        if self.encode_categ:\n","            if self.encode_categ == 'auto':\n","                self._auto_encode(df)\n","            elif isinstance(self.encode_categ, list):\n","                for col in self.encode_categ:\n","                    if col in df.columns:\n","                        self._auto_encode(df, col)\n","        return df\n","\n","    def _auto_encode(self, df, col=None):\n","        if col:\n","            if len(df[col].unique()) <= 10:\n","                df = pd.get_dummies(df, columns=[col], prefix=[col])\n","            else:\n","                le = LabelEncoder()\n","                df[col] = le.fit_transform(df[col])\n","        else:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col])\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df\n"],"metadata":{"id":"y_Nn-oCQR0QL","executionInfo":{"status":"ok","timestamp":1709570436225,"user_tz":-330,"elapsed":735,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["#@title master_class2\n","class AutoDataCleaner:\n","    def __init__(self, duplicates=True, missing_strategy=None, outliers_method=None,\n","                 threshold=3, scaling_method=None, extract_datetime=False, encode_categorical=None):\n","        self.duplicates = duplicates\n","        self.missing_strategy = missing_strategy\n","        self.outliers_method = outliers_method\n","        self.threshold = threshold\n","        self.scaling_method = scaling_method\n","        self.extract_datetime = extract_datetime\n","        self.encode_categorical = encode_categorical\n","\n","    def fit_transform(self, df):\n","        if self.duplicates:\n","            df = self.remove_duplicates(df)\n","        if self.missing_strategy:\n","            df = self.handle_missing_values(df)\n","        if self.outliers_method:\n","            df = self.handle_outliers(df)\n","        if self.scaling_method:\n","            df = self.adjust_scaling(df)\n","        if self.extract_datetime:\n","            df = self.convert_datetime(df)\n","        if self.encode_categorical:\n","            df = self.encode_categorical_features(df)\n","        return df\n","\n","    def remove_duplicates(self, df):\n","        df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","    def handle_missing_values(self, df):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        cat_cols = df.select_dtypes(include='object').columns\n","\n","        if 'auto' in self.missing_strategy:\n","            df[num_cols] = self.impute_missing_values(df[num_cols], strategy='numeric')\n","            df[cat_cols] = self.impute_missing_values(df[cat_cols], strategy='categorical')\n","\n","        return df\n","\n","    def impute_missing_values(self, df, strategy='numeric'):\n","        imputer = None\n","        if 'knn' in self.missing_strategy:\n","            if strategy == 'numeric':\n","                imputer = KNeighborsRegressor()\n","            elif strategy == 'categorical':\n","                imputer = KNeighborsClassifier()\n","        elif 'most_frequent' in self.missing_strategy:\n","            imputer = SimpleImputer(strategy='most_frequent')\n","\n","        if imputer:\n","            df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        return df\n","\n","    def handle_outliers(self, df):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","\n","        if 'knn' in self.outliers_method:\n","            df = self.handle_outliers_knn(df[num_cols])\n","        else:\n","            df = self.remove_outliers(df[num_cols])\n","\n","        return df\n","\n","    def handle_outliers_knn(self, df):\n","        imputer = KNNImputer()\n","        df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n","\n","        z_scores = np.abs(zscore(df_imputed))\n","        outlier_indices = np.any(z_scores > self.threshold, axis=1)\n","\n","        if np.any(outlier_indices):\n","            df_outliers = df_imputed[outlier_indices]\n","            df_outliers.fillna(df_outliers.mean(), inplace=True)\n","            df_imputed.loc[outlier_indices] = df_outliers\n","\n","        return df_imputed\n","\n","    def remove_outliers(self, df):\n","        if 'zscore' in self.outliers_method:\n","            z_scores = np.abs(zscore(df))\n","            df = df[(z_scores < self.threshold).all(axis=1)]\n","        elif 'iqr' in self.outliers_method:\n","            for col in df.columns:\n","                q1 = df[col].quantile(0.25)\n","                q3 = df[col].quantile(0.75)\n","                iqr = q3 - q1\n","                lower_bound = q1 - (self.threshold * iqr)\n","                upper_bound = q3 + (self.threshold * iqr)\n","                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","        return df\n","\n","    def adjust_scaling(self, df):\n","        scaler = None\n","        if 'minmax' in self.scaling_method:\n","            scaler = MinMaxScaler()\n","        elif 'standard' in self.scaling_method:\n","            scaler = StandardScaler()\n","        elif 'robust' in self.scaling_method:\n","            scaler = RobustScaler()\n","\n","        if scaler:\n","            df[df.columns] = scaler.fit_transform(df[df.columns])\n","        return df\n","\n","    def convert_datetime(self, df):\n","        cols = df.select_dtypes(include='datetime64').columns\n","        for col in cols:\n","            df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","            if self.extract_datetime != False:\n","                df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","\n","        return df\n","\n","    def encode_categorical_features(self, df):\n","        if 'auto' in self.encode_categorical:\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col])\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df\n","\n"],"metadata":{"id":"KwSASeQeR0S-","executionInfo":{"status":"ok","timestamp":1709570437725,"user_tz":-330,"elapsed":3,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["# Load CSV data into a DataFrame\n","df = pd.read_csv(\"kidney_disease.csv\")\n","\n","# Initialize AutoDataCleaner with desired configurations\n","cleaner = AutoDataCleaner(duplicates=True,\n","                           missing_strategy=['auto', 'most_frequent'],\n","                           outliers_method=['zscore', 'iqr'],\n","                           threshold=3,\n","                           scaling_method=['minmax', 'standard'],\n","                           extract_datetime=True,\n","                           encode_categorical='auto')\n","\n","# Apply data cleaning\n","cleaned_df = cleaner.fit_transform(df)"],"metadata":{"id":"QRb6Ch-aNlwp","executionInfo":{"status":"ok","timestamp":1709570439908,"user_tz":-330,"elapsed":552,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eZZD5hePSLyD","executionInfo":{"status":"ok","timestamp":1709570468175,"user_tz":-330,"elapsed":956,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"007f5360-2a13-4949-8bbb-2748e9ca4935"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 400 entries, 0 to 399\n","Data columns (total 26 columns):\n"," #   Column          Non-Null Count  Dtype  \n","---  ------          --------------  -----  \n"," 0   id              400 non-null    float64\n"," 1   age             400 non-null    float64\n"," 2   bp              400 non-null    float64\n"," 3   sg              400 non-null    float64\n"," 4   al              400 non-null    float64\n"," 5   su              400 non-null    float64\n"," 6   rbc             400 non-null    object \n"," 7   pc              400 non-null    object \n"," 8   pcc             400 non-null    object \n"," 9   ba              400 non-null    object \n"," 10  bgr             400 non-null    float64\n"," 11  bu              400 non-null    float64\n"," 12  sc              400 non-null    float64\n"," 13  sod             400 non-null    float64\n"," 14  pot             400 non-null    float64\n"," 15  hemo            400 non-null    float64\n"," 16  pcv             400 non-null    object \n"," 17  wc              400 non-null    object \n"," 18  rc              400 non-null    object \n"," 19  htn             400 non-null    object \n"," 20  dm              400 non-null    object \n"," 21  cad             400 non-null    object \n"," 22  appet           400 non-null    object \n"," 23  pe              400 non-null    object \n"," 24  ane             400 non-null    object \n"," 25  classification  400 non-null    object \n","dtypes: float64(12), object(14)\n","memory usage: 81.4+ KB\n","None\n"]}]},{"cell_type":"code","source":["print(cleaned_df.info())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g-cHHD1CVwYT","executionInfo":{"status":"ok","timestamp":1709570471621,"user_tz":-330,"elapsed":487,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"69bd816b-681e-4c27-8556-c99c8936d613"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 361 entries, 0 to 399\n","Data columns (total 12 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   id      361 non-null    float64\n"," 1   age     361 non-null    float64\n"," 2   bp      361 non-null    float64\n"," 3   sg      361 non-null    float64\n"," 4   al      361 non-null    float64\n"," 5   su      361 non-null    float64\n"," 6   bgr     361 non-null    float64\n"," 7   bu      361 non-null    float64\n"," 8   sc      361 non-null    float64\n"," 9   sod     361 non-null    float64\n"," 10  pot     361 non-null    float64\n"," 11  hemo    361 non-null    float64\n","dtypes: float64(12)\n","memory usage: 36.7 KB\n","None\n"]}]},{"cell_type":"code","source":["##########################################################################################\n","#@title master_class1\n","\n","class AutoDataCleaner:\n","    def __init__(self, duplicates=True, missing_strategy=None, outliers_method=None,\n","                 threshold=3, scaling_method=None, extract_datetime=False, encode_categorical=None):\n","        self.duplicates = duplicates\n","        self.missing_strategy = missing_strategy\n","        self.outliers_method = outliers_method\n","        self.threshold = threshold\n","        self.scaling_method = scaling_method\n","        self.extract_datetime = extract_datetime\n","        self.encode_categorical = encode_categorical\n","\n","    def fit_transform(self, df):\n","        if self.duplicates:\n","            df = self.remove_duplicates(df)\n","        if self.missing_strategy:\n","            df = self.handle_missing_values(df)\n","        if self.outliers_method:\n","            df = self.handle_outliers(df)\n","        if self.scaling_method:\n","            df = self.adjust_scaling(df)\n","        if self.extract_datetime:\n","            df = self.convert_datetime(df)\n","        if self.encode_categorical:\n","            df = self.encode_categorical_features(df)\n","        return df\n","\n","    def remove_duplicates(self, df):\n","        df.drop_duplicates(inplace=True, ignore_index=True)\n","        return df\n","\n","    def handle_missing_values(self, df):\n","        if self.missing_strategy == 'delete':\n","            df.dropna(inplace=True)\n","        elif self.missing_strategy == 'auto':\n","            df = self.impute_missing_values(df)\n","        return df\n","\n","    def impute_missing_values(self, df):\n","        imputer = None\n","        if 'knn' in self.missing_strategy:\n","            imputer = KNNImputer()\n","        elif 'most_frequent' in self.missing_strategy:\n","            imputer = SimpleImputer(strategy='most_frequent')\n","\n","        if imputer:\n","            df[df.columns] = imputer.fit_transform(df)\n","        return df\n","\n","    def handle_outliers(self, df):\n","        if self.outliers_method == 'zscore':\n","            df = self.remove_zscore_outliers(df)\n","        elif self.outliers_method == 'iqr':\n","            df = self.remove_iqr_outliers(df)\n","        return df\n","\n","    def remove_zscore_outliers(self, df):\n","        z_scores = np.abs(zscore(df))\n","        df = df[(z_scores < self.threshold).all(axis=1)]\n","        return df\n","\n","    def remove_iqr_outliers(self, df):\n","        num_cols = df.select_dtypes(include=np.number).columns\n","        for col in num_cols:\n","            q1 = df[col].quantile(0.25)\n","            q3 = df[col].quantile(0.75)\n","            iqr = q3 - q1\n","            lower_bound = q1 - (self.threshold * iqr)\n","            upper_bound = q3 + (self.threshold * iqr)\n","            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n","        return df\n","\n","    def adjust_scaling(self, df):\n","        scaler = None\n","        if self.scaling_method == 'minmax':\n","            scaler = MinMaxScaler()\n","        elif self.scaling_method == 'standard':\n","            scaler = StandardScaler()\n","        elif self.scaling_method == 'robust':\n","            scaler = RobustScaler()\n","\n","        if scaler:\n","            df[df.columns] = scaler.fit_transform(df[df.columns])\n","        return df\n","\n","    def convert_datetime(self, df):\n","        cols = set(df.columns) ^ set(df.select_dtypes(include=np.number).columns)\n","        for col in cols:\n","            try:\n","                df[col] = pd.to_datetime(df[col], infer_datetime_format=True)\n","                if self.extract_datetime != False:\n","                    df = df.join(pd.to_datetime(df[col]).dt.__getattribute__(self.extract_datetime))\n","            except:\n","                pass\n","        return df\n","\n","    def encode_categorical_features(self, df):\n","        if self.encode_categorical == 'auto':\n","            for col in df.select_dtypes(include='object'):\n","                if len(df[col].unique()) <= 10:\n","                    df = pd.get_dummies(df, columns=[col], prefix=[col])\n","                else:\n","                    le = LabelEncoder()\n","                    df[col] = le.fit_transform(df[col])\n","        return df"],"metadata":{"cellView":"form","id":"3l1O32RQNUi_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Set random seed for reproducibility\n","np.random.seed(21)\n","\n","# Generate synthetic dataset\n","num_samples = 1000\n","num_features = 10\n","\n","# Generate random data for each feature\n","data = {\n","    f'Feature_{i}': np.random.randn(num_samples) for i in range(1, num_features + 1)\n","}\n","\n","# Introduce missing values\n","missing_percentage = 0.1\n","for feature in data.keys():\n","    missing_indices = np.random.choice(num_samples, int(missing_percentage * num_samples), replace=False)\n","    data[feature][missing_indices] = np.nan\n","\n","# Introduce outliers\n","outlier_percentage = 0.05\n","for feature in data.keys():\n","    outlier_indices = np.random.choice(num_samples, int(outlier_percentage * num_samples), replace=False)\n","    data[feature][outlier_indices] = np.random.uniform(low=-10, high=10, size=len(outlier_indices))\n","\n","# Create DataFrame\n","df = pd.DataFrame(data)\n","\n","# Print some basic statistics\n","print(\"Basic statistics before preprocessing:\")\n","print(df.describe())\n","\n","# Save the dataset to a CSV file\n","df.to_csv('synthetic_dataset2.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8lH3f_DrS2kW","executionInfo":{"status":"ok","timestamp":1709569756125,"user_tz":-330,"elapsed":760,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"8bc4a3c4-f0a9-4920-ff7e-5aba8ed3bf53"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["Basic statistics before preprocessing:\n","        Feature_1   Feature_2   Feature_3   Feature_4   Feature_5   Feature_6  \\\n","count  902.000000  906.000000  905.000000  906.000000  901.000000  905.000000   \n","mean    -0.072030    0.005005    0.011028    0.098298   -0.013162   -0.059704   \n","std      1.651788    1.652416    1.759215    1.628810    1.740880    1.768028   \n","min     -9.842061   -9.281973   -9.539031   -9.952659   -9.900852   -9.973520   \n","25%     -0.715977   -0.709270   -0.694639   -0.663724   -0.728232   -0.701059   \n","50%      0.003219    0.009753    0.053530    0.011458    0.031356   -0.035066   \n","75%      0.689010    0.718652    0.740827    0.713994    0.777602    0.715739   \n","max      9.871996    9.862402    9.998826    9.888158    8.374322    9.135956   \n","\n","        Feature_7   Feature_8   Feature_9  Feature_10  \n","count  905.000000  905.000000  903.000000  908.000000  \n","mean     0.108368   -0.008339    0.048426    0.124866  \n","std      1.679392    1.822530    1.715898    1.625668  \n","min     -9.750495   -9.725475   -8.411844   -8.718473  \n","25%     -0.655081   -0.710085   -0.628521   -0.637975  \n","50%      0.067245    0.004198    0.060852    0.025390  \n","75%      0.833290    0.659510    0.712461    0.680741  \n","max      9.949627    9.976223    9.899260    9.909357  \n"]}]}]}