{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rZLZpPMAg-q2"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.impute import SimpleImputer, KNNImputer\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from scipy.stats import skew"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"9Xdxd5Lg88c5"},"outputs":[],"source":["#@title Preprocessing database\n","\n","irrelevant_columns = [\n","    \"ID\", \"id\", \"Index\", \"index\", \"Serial Number\", \"serial_number\",\n","    \"Address\", \"address\", \"Href\", \"href\", \"Timestamp\", \"timestamp\",\n","    \"Creation Date\", \"creation_date\", \"Last Updated Date\", \"last_updated_date\",\n","    \"Version\", \"version\", \"Checksum\", \"checksum\", \"Year\", \"year\"\n","    \"Row ID\", \"row_id\", \"Record ID\", \"record_id\", \"Customer ID\", \"customer_id\",\n","    \"Client ID\", \"client_id\", \"Account ID\", \"account_id\", \"Transaction ID\", \"transaction_id\",\n","    \"Email\", \"email\", \"Phone Number\", \"phone_number\", \"Website\", \"website\",\n","    \"Fax\", \"fax\", \"IP Address\", \"ip_address\", \"MAC Address\", \"mac_address\",\n","    \"Social Security Number\", \"social_security_number\", \"Driver's License\", \"drivers_license\",\n","    \"ID_\", \"id_\", \"Index_\", \"index_\", \"Serial_Number\", \"serial_number_\",\n","    \"Address_\", \"address_\", \"Href_\", \"href_\", \"Timestamp_\", \"timestamp_\",\n","    \"Creation_Date\", \"creation_date_\", \"Last_Updated_Date\", \"last_updated_date_\",\n","    \"Version_\", \"version_\", \"Checksum_\", \"checksum_\",\n","    \"Row_ID\", \"row_id_\", \"Record_ID\", \"record_id_\", \"Customer_ID\", \"customer_id_\",\n","    \"Client_ID\", \"client_id_\", \"Account_ID\", \"account_id_\", \"Transaction_ID\", \"transaction_id_\",\n","    \"Email_\", \"email_\", \"Phone_Number\", \"phone_number_\", \"Website_\", \"website_\",\n","    \"Fax_\", \"fax_\", \"IP_Address\", \"ip_address_\", \"MAC_Address\", \"mac_address_\",\n","    \"Social_Security_Number\", \"social_security_number_\", \"Driver's_License\", \"drivers_license_\"\n","]\n","\n","ordinal_data = {\n","    'low':1,\n","    'medium':2,\n","    'moderate':2,\n","    'high':3,\n","    # Education Level\n","    'high school diploma': 1,\n","    'associate\\'s degree': 2,\n","    'bachelor\\'s degree': 3,\n","    'master\\'s degree': 4,\n","    'doctorate degree': 5,\n","    # Income Level\n","    'low income': 1,\n","    'middle income': 2,\n","    'high income': 3,\n","    # Customer Satisfaction\n","    'very dissatisfied': 1,\n","    'dissatisfied': 2,\n","    'neutral': 3,\n","    'satisfied': 4,\n","    'very satisfied': 5,\n","    # Likert Scale\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neither agree nor disagree': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Job Seniority\n","    'entry-level': 1,\n","    'mid-level': 2,\n","    'senior-level': 3,\n","    'executive-level': 4,\n","    # Severity of Illness/Condition\n","    'mild': 1,\n","    'moderate': 2,\n","    'severe': 3,\n","    # Temperature\n","    'cold': 1,\n","    'warm': 2,\n","    'hot': 3,\n","    'very hot': 4,\n","    # Customer Rating\n","    '1 star': 1,\n","    '2 stars': 2,\n","    '3 stars': 3,\n","    '4 stars': 4,\n","    '5 stars': 5,\n","    # Likelihood of Purchase\n","    'very unlikely': 1,\n","    'unlikely': 2,\n","    'likely': 4,\n","    'very likely': 5,\n","    # Degree of Agreement\n","    'strongly disagree': 1,\n","    'disagree': 2,\n","    'neutral': 3,\n","    'agree': 4,\n","    'strongly agree': 5,\n","    # Pain Scale\n","    'no pain': 1,\n","    'mild pain': 2,\n","    'moderate pain': 3,\n","    'severe pain': 4,\n","    'extreme pain': 5,\n","    # Likelihood of Recommendation\n","    'very unlikely to recommend': 1,\n","    'unlikely to recommend': 2,\n","    'likely to recommend': 4,\n","    'very likely to recommend': 5,\n","    # Quality Ratings\n","    'poor quality': 1,\n","    'fair quality': 2,\n","    'good quality': 3,\n","    'very good quality': 4,\n","    'excellent quality': 5,\n","    # Customer Service Experience\n","    'very poor': 1,\n","    'poor': 2,\n","    'average': 3,\n","    'good': 4,\n","    'excellent': 5,\n","    # Ease of Use\n","    'very difficult': 1,\n","    'difficult': 2,\n","    'easy': 4,\n","    'very easy': 5,\n","    # Likelihood of Churn\n","    'very unlikely to churn': 1,\n","    'unlikely to churn': 2,\n","    'likely to churn': 4,\n","    'very likely to churn': 5,\n","    # Satisfaction with Product/Service\n","    'not satisfied': 1,\n","    'slightly satisfied': 2,\n","    'moderately satisfied': 3,\n","    'extremely satisfied': 5,\n","    # Risk Levels\n","    'low risk': 1,\n","    'moderate risk': 2,\n","    'high risk': 3,\n","    # Performance Ratings\n","    'below expectations': 1,\n","    'meeting expectations': 2,\n","    'exceeding expectations': 3 }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g-AZviCQEmkD","cellView":"form"},"outputs":[],"source":["#@title Data Preprocessing\n","\n","def remove_irrelevant_columns(data, irrelevant_columns):\n","  columns_to_delete = [col for col in data.columns if col in irrelevant_columns]\n","\n","  if len(columns_to_delete)>0:\n","    data.drop(columns=columns_to_delete, inplace=True)\n","\n","  return data\n","\n","\n","def remove_duplicate_values(data):\n","  if data.duplicated().any():\n","    data.drop_duplicates(inplace=True)\n","\n","  return data\n","\n","\n","def remove_constant_values(data):\n","  constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n","\n","  if len(constant_columns) > 0:\n","    data.drop(columns=constant_columns, inplace=True)\n","\n","  return data\n","\n","\n","def remove_string_numerical(data):\n","  string_num_cols = [col for col in data.columns if data[col].dtype == 'object' and data[col].str.isnumeric().all()]\n","\n","  if len(string_num_cols) > 0:\n","    data[string_num_cols] = data[string_num_cols].apply(pd.to_numeric)\n","\n","  return data\n","\n","\n","def remove_object_numerical(data):\n","  import re\n","  object_cols = data.select_dtypes(include=['object']).columns\n","\n","  if len(object_cols) > 0:\n","    for col in object_cols:\n","      numerical_values = data[col].apply(lambda x: re.findall(r'\\d+\\.\\d+|\\d+', str(x)))\n","      numeric_col = col + '_numeric'\n","      data[numeric_col] = numerical_values.apply(lambda x: float(x[0]) if x else None)\n","\n","  return data\n","\n","\n","def missing_values(data, threshold=0.5, k_neighbors=5):\n","  numerical_cols = data.select_dtypes(include=['number']).columns\n","  categorical_cols = data.select_dtypes(include=['object']).columns\n","\n","  if data.isnull().any().any():\n","      missing_percentage = data.isnull().mean()\n","\n","      if (missing_percentage > threshold).any():\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","        strategy = 'knn'\n","      else:\n","        imputer = SimpleImputer(strategy='mean')\n","        strategy = 'mean'\n","      if strategy == 'knn':\n","        imputer = KNNImputer(n_neighbors=k_neighbors)\n","      else:\n","        imputer = SimpleImputer(strategy=strategy)\n","      data[numerical_cols] = imputer.fit_transform(data[numerical_cols])\n","      mode_imputer = SimpleImputer(strategy='most_frequent')\n","      data[categorical_cols] = mode_imputer.fit_transform(data[categorical_cols])\n","\n","  return data\n","\n","\n","# def convert_datetime(data):\n","#     object_cols = data.select_dtypes(include=['object']).columns\n","\n","#     if len(object_cols) > 0:\n","#         for col in object_cols:\n","#             try:\n","#                 data[col] = pd.to_datetime(data[col])\n","#                 data[col + '_numeric'] = data[col].astype('int64') // 10**9\n","#                 data.drop(columns=[col], inplace=True)\n","#             except (ValueError, TypeError):\n","#                 pass\n","\n","#     return data\n","\n","\n","def encode_objects(data):\n","  categorical_columns = data.select_dtypes(include=['object']).columns\n","\n","  if len(categorical_columns) > 0:\n","    for col in categorical_columns:\n","      unique_values_count = data[col].nunique()\n","\n","      if unique_values_count == 2:\n","        encoder = LabelEncoder()\n","        data[col] = encoder.fit_transform(data[col])\n","\n","      elif unique_values_count <= 7:\n","          if all(value in ordinal_data for value in data[col].str.lower()):\n","            data[col] = data[col].str.lower().map(ordinal_data)\n","          elif any(word in data[col].str.lower() for word in ['low', 'medium', 'moderate', 'high']):\n","            data[col] = data[col].apply(lambda x: ordinal_data[x.lower()] if x.lower() in ordinal_data else x)\n","          else:\n","            encoder = OneHotEncoder(sparse_output=False, drop='first')\n","            encoded_values = encoder.fit_transform(data[[col]])\n","            col_names = [f\"{col}_{value}\" for value in encoder.categories_[0][1:]]\n","            df = pd.DataFrame(encoded_values, columns=col_names)\n","            data = pd.concat([data, df], axis=1)\n","            data.drop(columns=[col], inplace=True)\n","\n","  return data\n","\n","\n","def adjust_values(data):\n","  scaler = StandardScaler()\n","  scaler.fit_transform(data)\n","\n","  return data\n","\n","\n","#master function\n","def automatic_data_preprocessing(data, threshold=0.5, k_neighbors=5):\n","\n","    data = remove_irrelevant_columns(data, irrelevant_columns)\n","    data = remove_duplicate_values(data)\n","    data = remove_constant_values(data)\n","    data = remove_string_numerical(data)\n","    data = remove_object_numerical(data)\n","    data = missing_values(data, threshold, k_neighbors)\n","    # data = convert_datetime(data)\n","    data = encode_objects(data)\n","    data = adjust_values(data)\n","\n","    return data"]},{"cell_type":"code","source":["#@title Feature selection\n","from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n","\n","def feature_selection(X, y, k=10, problem_type):\n","    if problem_type == 'classification':\n","        selector = SelectKBest(score_func=f_classif, k=k)\n","    elif problem_type == 'regression':\n","        selector = SelectKBest(score_func=f_regression, k=k)\n","    else:\n","        raise ValueError(\"Invalid problem type. Use 'Classification' or 'Regression' !!\")\n","\n","    X_new = selector.fit_transform(X, y)\n","    selected_features_indices = selector.get_support(indices=True)\n","    selected_features_names = X.columns[selected_features_indices].tolist()\n","\n","    return X_new, selected_features_names\n","\n","# Example usage for classification\n","data_c = pd.read_csv('stroke_data.csv')\n","cdata = automatic_data_preprocessing(data_c)\n","X_train = cdata.drop('stroke', axis=1)\n","y_train = cdata['stroke']\n","\n","X_train_selected, selected_features = feature_selection_filter_method(X_train, y_train, problem_type='classification')\n","\n","print(\"Selected Features (Classification):\", selected_features)\n","\n","# Example usage for regression\n","data_r = pd.read_csv('audiA1_price_data.csv')\n","rdata = automatic_data_preprocessing(data_r)\n","X_train_r = rdata.drop('Price(£)', axis=1)\n","y_train_r = rdata['Price(£)']\n","\n","X_train_selected_r, selected_features_r = feature_selection_filter_method(X_train_r, y_train_r, problem_type='regression')\n","\n","print(\"\\nSelected Features (Regression):\", selected_features_r)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nLbbjU1c8vo","executionInfo":{"status":"ok","timestamp":1712492401370,"user_tz":-330,"elapsed":15,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"e54fe597-c08c-4f12-a9b3-62a1d9eb0b9b","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected Features (Classification): ['age', 'hypertension', 'heart_disease', 'ever_married', 'Residence_type', 'avg_glucose_level', 'bmi', 'work_type_Self-employed', 'work_type_children', 'smoking_status_formerly smoked']\n","\n","Selected Features (Regression): ['Mileage(miles)', 'Transmission', 'Fuel', 'Number_of_Owners', 'MileageRank', 'PriceRank', 'Engine_numeric', 'Engine_1.4L', 'Engine_1.5L', 'Engine_1.6L']\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1712420846003,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"},"user_tz":-330},"id":"U-Omy0uE88Ws","outputId":"92ef7082-0dc6-4a7e-b2eb-6e2569eef49a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Duplicate Values: 0\n","\n","Features with Null Values: []\n","\n","Data Types: [dtype('int64') dtype('float64') dtype('O')]\n","\n","Unique values in 'index': 471\n","Unique values in 'Year': 9\n","Unique values in 'Type': 1\n","Unique values in 'Mileage(miles)': 416\n","Unique values in 'Engine': 6\n","Unique values in 'PS': 28\n","Unique values in 'Transmission': 2\n","Unique values in 'Fuel': 2\n","Unique values in 'Number_of_Owners': 7\n","Unique values in 'href': 471\n","Unique values in 'PPY': 406\n","Unique values in 'MileageRank': 471\n","Unique values in 'PriceRank': 471\n","Unique values in 'PPYRank': 471\n","Unique values in 'Score': 306\n","Unique values in 'Price(£)': 356\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 471 entries, 0 to 470\n","Data columns (total 16 columns):\n"," #   Column            Non-Null Count  Dtype  \n","---  ------            --------------  -----  \n"," 0   index             471 non-null    int64  \n"," 1   Year              471 non-null    float64\n"," 2   Type              471 non-null    object \n"," 3   Mileage(miles)    471 non-null    float64\n"," 4   Engine            471 non-null    object \n"," 5   PS                471 non-null    float64\n"," 6   Transmission      471 non-null    object \n"," 7   Fuel              471 non-null    object \n"," 8   Number_of_Owners  471 non-null    int64  \n"," 9   href              471 non-null    object \n"," 10  PPY               471 non-null    float64\n"," 11  MileageRank       471 non-null    int64  \n"," 12  PriceRank         471 non-null    int64  \n"," 13  PPYRank           471 non-null    int64  \n"," 14  Score             471 non-null    int64  \n"," 15  Price(£)          471 non-null    float64\n","dtypes: float64(5), int64(6), object(5)\n","memory usage: 59.0+ KB\n","None\n"]}],"source":["dataset = pd.read_csv('audiA1_price_data.csv')\n","\n","num_duplicates = dataset.duplicated().sum()\n","print('Number of Duplicate Values:', num_duplicates)\n","print()\n","null_columns = dataset.columns[dataset.isnull().any()]\n","print('Features with Null Values:', null_columns.tolist())\n","print()\n","print('Data Types:', dataset.dtypes.unique())\n","print()\n","for column_name in dataset.columns:\n","    unique_values = dataset[column_name].nunique()\n","    print(f\"Unique values in '{column_name}': {unique_values}\")\n","print()\n","print(dataset.info())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hF3t5cev88UY","executionInfo":{"status":"ok","timestamp":1712420846004,"user_tz":-330,"elapsed":38,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"464e39af-fb8c-49dc-8d1c-aad576b746c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Duplicate Values: 0\n","\n","Features with Null Values: []\n","\n","Data Types: [dtype('float64') dtype('int64')]\n","\n","Unique values in 'Mileage(miles)': 416\n","Unique values in 'PS': 28\n","Unique values in 'Transmission': 2\n","Unique values in 'Fuel': 2\n","Unique values in 'Number_of_Owners': 7\n","Unique values in 'PPY': 406\n","Unique values in 'MileageRank': 471\n","Unique values in 'PriceRank': 471\n","Unique values in 'PPYRank': 471\n","Unique values in 'Score': 306\n","Unique values in 'Price(£)': 356\n","Unique values in 'Engine_numeric': 6\n","Unique values in 'Transmission_numeric_numeric': 1\n","Unique values in 'Fuel_numeric_numeric': 1\n","Unique values in 'Engine_1.2L': 2\n","Unique values in 'Engine_1.4L': 2\n","Unique values in 'Engine_1.5L': 2\n","Unique values in 'Engine_1.6L': 2\n","Unique values in 'Engine_2.0L': 2\n","\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 471 entries, 0 to 470\n","Data columns (total 19 columns):\n"," #   Column                        Non-Null Count  Dtype  \n","---  ------                        --------------  -----  \n"," 0   Mileage(miles)                471 non-null    float64\n"," 1   PS                            471 non-null    float64\n"," 2   Transmission                  471 non-null    int64  \n"," 3   Fuel                          471 non-null    int64  \n"," 4   Number_of_Owners              471 non-null    float64\n"," 5   PPY                           471 non-null    float64\n"," 6   MileageRank                   471 non-null    float64\n"," 7   PriceRank                     471 non-null    float64\n"," 8   PPYRank                       471 non-null    float64\n"," 9   Score                         471 non-null    float64\n"," 10  Price(£)                      471 non-null    float64\n"," 11  Engine_numeric                471 non-null    float64\n"," 12  Transmission_numeric_numeric  471 non-null    int64  \n"," 13  Fuel_numeric_numeric          471 non-null    int64  \n"," 14  Engine_1.2L                   471 non-null    float64\n"," 15  Engine_1.4L                   471 non-null    float64\n"," 16  Engine_1.5L                   471 non-null    float64\n"," 17  Engine_1.6L                   471 non-null    float64\n"," 18  Engine_2.0L                   471 non-null    float64\n","dtypes: float64(15), int64(4)\n","memory usage: 70.0 KB\n","None\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-37-60a9edd0b64e>:80: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  data[col] = pd.to_datetime(data[col])\n","<ipython-input-37-60a9edd0b64e>:80: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  data[col] = pd.to_datetime(data[col])\n","<ipython-input-37-60a9edd0b64e>:80: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  data[col] = pd.to_datetime(data[col])\n","/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["preprocessed_data = automatic_data_preprocessing(dataset)\n","\n","num_duplicate = preprocessed_data.duplicated().sum()\n","print('Number of Duplicate Values:', num_duplicate)\n","print()\n","null_column = preprocessed_data.columns[preprocessed_data.isnull().any()]\n","print('Features with Null Values:', null_column.tolist())\n","print()\n","print('Data Types:', preprocessed_data.dtypes.unique())\n","print()\n","for column_name in preprocessed_data.columns:\n","    unique_values = preprocessed_data[column_name].nunique()\n","    print(f\"Unique values in '{column_name}': {unique_values}\")\n","print()\n","print(preprocessed_data.info())"]},{"cell_type":"code","source":[],"metadata":{"id":"RnljqYtec8-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w-58-s8Zc86v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q2nEqV6Xc81H"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMBubnp/r0M9Fd4L8QnvayD"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}