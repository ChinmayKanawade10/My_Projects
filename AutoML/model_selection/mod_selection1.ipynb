{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNlMKE8/V/HSGfUzgly9t+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# !pip install bayesian-optimization"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"buEE40RRnWSe","executionInfo":{"status":"ok","timestamp":1712460764180,"user_tz":-330,"elapsed":8202,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"7da99bf6-3591-4da6-a4bc-1d39c1906123"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bayesian-optimization\n","  Downloading bayesian_optimization-1.4.3-py3-none-any.whl (18 kB)\n","Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.25.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.11.4)\n","Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from bayesian-optimization) (1.2.2)\n","Collecting colorama>=0.4.6 (from bayesian-optimization)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.4.0)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-1.4.3 colorama-0.4.6\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n","from sklearn.metrics import r2_score, accuracy_score\n","import time"],"metadata":{"id":"Nw9dvMq_uaqG","executionInfo":{"status":"ok","timestamp":1712546430050,"user_tz":-330,"elapsed":1958,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# data = pd.read_csv('Zboson_decay_data.csv')\n","\n","# print(\"Column Names with Indexes:\")\n","# for idx, col_name in enumerate(data.columns):\n","#     print(f\"Index {idx}: {col_name}\")\n","# target_col_idx = int(input(\"Enter the index of the target variable column: \"))\n","\n","# X = data.drop(data.columns[target_col_idx], axis=1)\n","# y = data.iloc[:, target_col_idx]\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11 )\n","\n","# print()\n","# print(\"Target Variable (y):\", data.columns[target_col_idx])"],"metadata":{"id":"sJhWUGVcuIxa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Set random seed for reproducibility\n","np.random.seed(42)\n","\n","# Generate random data for 10 features\n","num_samples = 50000\n","features = {}\n","for i in range(1, 11):\n","    feature_name = f'feature_{i}'\n","    if i % 2 == 0:\n","        # Generate values in a smaller range for even-numbered features\n","        features[feature_name] = np.random.uniform(0, 100, num_samples)\n","    else:\n","        # Generate values in a larger range for odd-numbered features\n","        features[feature_name] = np.random.uniform(0, 1000, num_samples)\n","\n","# Create a DataFrame for the features\n","df = pd.DataFrame(features)\n","\n","# Generate random values for the target variable\n","df['target'] = np.random.uniform(100, 1000, num_samples)\n","\n","# Save the DataFrame to a CSV file\n","df.to_csv('regression_data.csv', index=False)\n","\n"],"metadata":{"id":"QQg_bgH3tRo_","executionInfo":{"status":"ok","timestamp":1712546393930,"user_tz":-330,"elapsed":3471,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('regression_data.csv')\n","num_data = data.select_dtypes(include=['int64', 'float64'])\n","\n","print(\"Column Names with Indexes:\")\n","for idx, col_name in enumerate(num_data.columns):\n","    print(f\"Index {idx}: {col_name}\")\n","target_col_idx = int(input(\"Enter the index of the target variable column: \"))\n","\n","X = num_data.drop(num_data.columns[target_col_idx], axis=1)\n","y = num_data.iloc[:, target_col_idx]\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11 )\n","\n","print()\n","print(\"Target Variable (y):\", data.columns[target_col_idx])"],"metadata":{"id":"yhGsbT8yqbI2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712546443593,"user_tz":-330,"elapsed":2912,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"d9d87364-f123-47c6-bde0-dfbc5609beca"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Column Names with Indexes:\n","Index 0: feature_1\n","Index 1: feature_2\n","Index 2: feature_3\n","Index 3: feature_4\n","Index 4: feature_5\n","Index 5: feature_6\n","Index 6: feature_7\n","Index 7: feature_8\n","Index 8: feature_9\n","Index 9: feature_10\n","Index 10: target\n","Enter the index of the target variable column: 10\n","\n","Target Variable (y): target\n"]}]},{"cell_type":"code","execution_count":10,"metadata":{"id":"S6u8nhMkgAkS","colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"status":"error","timestamp":1712546829163,"user_tz":-330,"elapsed":57603,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"848e95aa-269f-402b-ec58-4e459bf8d304"},"outputs":[{"output_type":"stream","name":"stdout","text":["Continuous target variable detected !\n","Algorithm selected : Regression\n","[('DecisionTreeRegressor', DecisionTreeRegressor()), ('RandomForestRegressor', RandomForestRegressor()), ('GradientBoostingRegressor', GradientBoostingRegressor())]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-15b1d62f5cb3>\u001b[0m in \u001b[0;36m<cell line: 91>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Model selected : {best_model}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-15b1d62f5cb3>\u001b[0m in \u001b[0;36mmodel_selection\u001b[0;34m(models, X, y, problem_type)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r2'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Regression'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mmean_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproblem_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Regression'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmean_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    474\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1792\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1793\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \"\"\"\n\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    377\u001b[0m             )\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["def algorithm_type(x_var, y_var):\n","    from sklearn.utils.multiclass import type_of_target\n","    dtype = y_var.dtype\n","    target_type = type_of_target(y_var)\n","\n","    if dtype == 'object' or target_type == 'binary':\n","      problem_type = 'Classification'\n","      print('Object or Binary target variable detected !')\n","\n","    elif target_type == 'continuous':\n","      problem_type = 'Regression'\n","      print('Continuous target variable detected !')\n","\n","    elif dtype in ['int64','float64'] or target_type in ['multiclass']:\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.23, random_state=42)\n","        rf_classifier = RandomForestClassifier()\n","        rf_regressor = RandomForestRegressor()\n","        rf_classifier.fit(X_train, y_train)\n","        rf_regressor.fit(X_train, y_train)\n","        classifier_score = rf_classifier.score(X_test, y_test)\n","        regressor_score = rf_regressor.score(X_test, y_test)\n","        if classifier_score > regressor_score:\n","            problem_type = 'Classification'\n","        else:\n","            problem_type = 'Regression'\n","        print(f'CS:{classifier_score} , RS:{regressor_score}')\n","\n","    else:\n","        user_input = input('''Specify problem type manually -\n","        (r for Regression / c for Classification) : ''')\n","\n","        if user_input == 'r': problem_type = 'Regression'\n","        elif user_input == 'c': problem_type = 'Classification'\n","        else: print('Select either Regression or Classification !')\n","\n","    return problem_type\n","\n","\n","def model_analysis(ptype):\n","    if ptype.lower() in ['Regression','regression', 'r']:\n","        models = [\n","            ('DecisionTreeRegressor', DecisionTreeRegressor()),\n","            ('RandomForestRegressor', RandomForestRegressor()),\n","            ('GradientBoostingRegressor', GradientBoostingRegressor())\n","        ]\n","    elif ptype.lower() in ['Classification','classification', 'c']:\n","        models = [\n","            ('DecisionTreeClassifier', DecisionTreeClassifier()),\n","            ('RandomForestClassifier', RandomForestClassifier()),\n","            ('GradientBoostingClassifier', GradientBoostingClassifier())\n","        ]\n","    else:\n","        raise ValueError('Invalid problem type specified.')\n","\n","    return models\n","\n","\n","def model_selection(models, X, y, problem_type):\n","    cv_start = time.time()\n","\n","    # if len(X) < 25000:  cv = 4\n","    # elif 25000 <= len(X) <= 50000:  cv = 3\n","    # else: cv = 2\n","    cv = 2\n","\n","    from sklearn.metrics import accuracy_score, r2_score\n","    best_model = None\n","    best_score = float('-inf') if problem_type == 'Regression' else 0\n","\n","    for name, model in models:\n","        scoring = 'r2' if problem_type == 'Regression' else 'accuracy'\n","        scores = cross_val_score(model, X, y, scoring=scoring, cv=cv)\n","        mean_score = scores.mean()\n","        if problem_type == 'Regression' and mean_score > best_score:\n","            best_score = mean_score\n","            best_model = model\n","        elif problem_type == 'Classification' and mean_score > best_score:\n","            best_score = mean_score\n","            best_model = model\n","    cv_end = time.time()\n","    print(f'CV time : {cv_end-cv_start}')\n","    return best_model\n","\n","\n","algorithm = algorithm_type(X, y)\n","print(f'Algorithm selected : {algorithm}')\n","\n","models = model_analysis(algorithm)\n","print(models)\n","\n","best_model = model_selection(models, X, y, algorithm)\n","print(f'Model selected : {best_model}')\n","\n","\n","def optimize_model(algorithm, model):\n","    print(algorithm)\n","    print(model)\n","\n","    if algorithm in ['Regression','regression']:\n","      if isinstance(model, DecisionTreeRegressor):\n","        print('Optimize DTR !!')\n","      elif isinstance(model, RandomForestRegressor):\n","        print('Optimize RFR !!')\n","      elif isinstance(model, GradientBoostingRegressor):\n","        print('Optimize GBR !!')\n","\n","    elif algorithm in ['Classification','classification']:\n","      if isinstance(model, DecisionTreeClassifier):\n","        print('Optimize DTC !!')\n","      elif isinstance(model, RandomForestClassifier):\n","        print('Optimize RFC !!')\n","      elif isinstance(model, GradientBoostingClassifier):\n","        print('Optimize GBC !!')\n","\n","    else:\n","      print('No model selected !!')\n","\n","optimize_model(algorithm, best_model)"]},{"cell_type":"code","source":["# Random Forest Regressor Optimization\n","from bayes_opt import BayesianOptimization\n","def optimize_rfr(X_train, X_test, y_train, y_test):\n","    def optimize_rfr_inner(n_estimators, max_depth, min_samples_split, min_samples_leaf):\n","        rfr = RandomForestRegressor(n_estimators=int(n_estimators), max_depth=int(max_depth),\n","                                     min_samples_split=int(min_samples_split), min_samples_leaf=int(min_samples_leaf))\n","        rfr.fit(X_train, y_train)\n","        y_pred = rfr.predict(X_test)\n","        return r2_score(y_test, y_pred)\n","\n","    rfr_bounds = {'n_estimators': (10, 100), 'max_depth': (1, 50), 'min_samples_split': (2, 20),\n","                  'min_samples_leaf': (1, 20)}\n","\n","    bayes_rfr = BayesianOptimization(f=optimize_rfr_inner, pbounds=rfr_bounds, random_state=42)\n","    bayes_rfr.maximize(init_points=10, n_iter=10)\n","\n","    return bayes_rfr, bayes_rfr.max['target']\n","\n","def optimize_model(algorithm, model, X_train, X_test, y_train, y_test):\n","    print(algorithm)\n","    print(model)\n","\n","    if algorithm in ['Regression','regression']:\n","      if isinstance(model, DecisionTreeRegressor):\n","          optimized_model = optimize_dtr(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, RandomForestRegressor):\n","          optimized_model = optimize_rfr(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, GradientBoostingRegressor):\n","          optimized_model = optimize_gbr(X_train, X_test, y_train, y_test)\n","\n","    elif algorithm in ['Classification','classification']:\n","      if isinstance(model, DecisionTreeClassifier):\n","          optimized_model = optimize_dtc(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, RandomForestClassifier):\n","          optimized_model = optimize_rfc(X_train, X_test, y_train, y_test)\n","      elif isinstance(model, GradientBoostingClassifier):\n","          optimized_model = optimize_gbc(X_train, X_test, y_train, y_test)\n","\n","    else:\n","        print('No model selected !!')\n","        optimized_model = None\n","\n","    return optimized_model\n","\n","final_model, performance = optimize_model(algorithm, best_model, X_train, X_test, y_train, y_test)\n","print(f\"Model : {best_model}\")\n","print(f\"Performance : {performance}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p7BGBCN2eJhn","executionInfo":{"status":"ok","timestamp":1712461155727,"user_tz":-330,"elapsed":16009,"user":{"displayName":"Chinmay Kanawade","userId":"02462673596510628563"}},"outputId":"295e3b38-3ccd-4129-b3b7-c6b4d793c74c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Regression\n","RandomForestRegressor()\n","|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n","-------------------------------------------------------------------------\n","| \u001b[0m1        \u001b[0m | \u001b[0m0.9897   \u001b[0m | \u001b[0m19.35    \u001b[0m | \u001b[0m19.06    \u001b[0m | \u001b[0m15.18    \u001b[0m | \u001b[0m63.88    \u001b[0m |\n","| \u001b[95m2        \u001b[0m | \u001b[95m0.9999   \u001b[0m | \u001b[95m8.645    \u001b[0m | \u001b[95m3.964    \u001b[0m | \u001b[95m3.046    \u001b[0m | \u001b[95m87.96    \u001b[0m |\n","| \u001b[0m3        \u001b[0m | \u001b[0m0.9976   \u001b[0m | \u001b[0m30.45    \u001b[0m | \u001b[0m14.45    \u001b[0m | \u001b[0m2.371    \u001b[0m | \u001b[0m97.29    \u001b[0m |\n","| \u001b[0m4        \u001b[0m | \u001b[0m0.9997   \u001b[0m | \u001b[0m41.79    \u001b[0m | \u001b[0m5.034    \u001b[0m | \u001b[0m5.273    \u001b[0m | \u001b[0m26.51    \u001b[0m |\n","| \u001b[0m5        \u001b[0m | \u001b[0m0.9989   \u001b[0m | \u001b[0m15.91    \u001b[0m | \u001b[0m10.97    \u001b[0m | \u001b[0m9.775    \u001b[0m | \u001b[0m36.21    \u001b[0m |\n","| \u001b[0m6        \u001b[0m | \u001b[0m0.9999   \u001b[0m | \u001b[0m30.98    \u001b[0m | \u001b[0m3.65     \u001b[0m | \u001b[0m7.259    \u001b[0m | \u001b[0m42.97    \u001b[0m |\n","| \u001b[0m7        \u001b[0m | \u001b[0m0.9971   \u001b[0m | \u001b[0m23.35    \u001b[0m | \u001b[0m15.92    \u001b[0m | \u001b[0m5.594    \u001b[0m | \u001b[0m56.28    \u001b[0m |\n","| \u001b[0m8        \u001b[0m | \u001b[0m0.9997   \u001b[0m | \u001b[0m30.03    \u001b[0m | \u001b[0m1.883    \u001b[0m | \u001b[0m12.94    \u001b[0m | \u001b[0m25.35    \u001b[0m |\n","| \u001b[0m9        \u001b[0m | \u001b[0m0.9891   \u001b[0m | \u001b[0m4.188    \u001b[0m | \u001b[0m19.03    \u001b[0m | \u001b[0m19.38    \u001b[0m | \u001b[0m82.76    \u001b[0m |\n","| \u001b[0m10       \u001b[0m | \u001b[0m0.9995   \u001b[0m | \u001b[0m15.93    \u001b[0m | \u001b[0m2.856    \u001b[0m | \u001b[0m14.32    \u001b[0m | \u001b[0m49.61    \u001b[0m |\n","| \u001b[0m11       \u001b[0m | \u001b[0m0.9889   \u001b[0m | \u001b[0m47.01    \u001b[0m | \u001b[0m19.86    \u001b[0m | \u001b[0m19.27    \u001b[0m | \u001b[0m10.53    \u001b[0m |\n","| \u001b[0m12       \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m3.412    \u001b[0m | \u001b[0m1.351    \u001b[0m | \u001b[0m12.81    \u001b[0m | \u001b[0m75.14    \u001b[0m |\n","| \u001b[0m13       \u001b[0m | \u001b[0m0.8056   \u001b[0m | \u001b[0m1.219    \u001b[0m | \u001b[0m1.767    \u001b[0m | \u001b[0m10.4     \u001b[0m | \u001b[0m41.69    \u001b[0m |\n","| \u001b[0m14       \u001b[0m | \u001b[0m0.9988   \u001b[0m | \u001b[0m17.68    \u001b[0m | \u001b[0m10.25    \u001b[0m | \u001b[0m9.118    \u001b[0m | \u001b[0m35.94    \u001b[0m |\n","| \u001b[0m15       \u001b[0m | \u001b[0m0.9978   \u001b[0m | \u001b[0m24.95    \u001b[0m | \u001b[0m12.52    \u001b[0m | \u001b[0m19.9     \u001b[0m | \u001b[0m45.53    \u001b[0m |\n","| \u001b[0m16       \u001b[0m | \u001b[0m0.9994   \u001b[0m | \u001b[0m27.11    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m15.61    \u001b[0m | \u001b[0m58.8     \u001b[0m |\n","| \u001b[0m17       \u001b[0m | \u001b[0m0.9907   \u001b[0m | \u001b[0m22.26    \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m17.04    \u001b[0m | \u001b[0m26.87    \u001b[0m |\n","| \u001b[0m18       \u001b[0m | \u001b[0m0.9998   \u001b[0m | \u001b[0m24.3     \u001b[0m | \u001b[0m5.02     \u001b[0m | \u001b[0m4.908    \u001b[0m | \u001b[0m77.94    \u001b[0m |\n","| \u001b[0m19       \u001b[0m | \u001b[0m0.9993   \u001b[0m | \u001b[0m21.16    \u001b[0m | \u001b[0m3.442    \u001b[0m | \u001b[0m16.27    \u001b[0m | \u001b[0m92.46    \u001b[0m |\n","| \u001b[0m20       \u001b[0m | \u001b[0m0.9988   \u001b[0m | \u001b[0m43.23    \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m20.0     \u001b[0m | \u001b[0m37.43    \u001b[0m |\n","=========================================================================\n","Model : RandomForestRegressor()\n","Performance : 0.9999233680541719\n"]}]}]}